{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from pypfopt import EfficientFrontier, expected_returns\n",
    "from pypfopt import risk_models\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "\n",
    "import quantstats as qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### _P1_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Optimización para maximizar el ratio Sharpe\\ndef optimize_max_sharpe(returns, cov_matrix, risk_free_rate=0.0, save_weights=False):\\n    num_assets = len(returns)\\n    def neg_sharpe_ratio(weights):\\n        p_return = np.dot(weights, returns)\\n        p_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\\n        return - (p_return - risk_free_rate) / p_volatility\\n    \\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\\n    bounds = tuple((0, 1) for asset in range(num_assets))\\n    \\n    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets],\\n                          method='SLSQP', bounds=bounds, constraints=constraints)\\n    \\n    if save_weights:\\n        return result.x\\n    return result\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Función para calcular un portafolio con límite de riesgo fijo\n",
    "def calculate_risk_limit(prices, risk_limit=0.02, save_weights=False):\n",
    "    vol = prices.pct_change().rolling(window=30).std() * np.sqrt(252)\n",
    "    weights = vol.mean(axis=1).apply(lambda x: 0.6 if x < risk_limit else 0.4)\n",
    "    if save_weights:\n",
    "        return\n",
    "    # Multiplica precios históricos por los pesos para obtener valores ponderados\n",
    "    return prices.mul(weights, axis=1).sum(axis=1)\n",
    "\"\"\"\n",
    "\"\"\"# Optimización para maximizar el ratio Sharpe\n",
    "def optimize_max_sharpe(returns, cov_matrix, risk_free_rate=0.0, save_weights=False):\n",
    "    num_assets = len(returns)\n",
    "    def neg_sharpe_ratio(weights):\n",
    "        p_return = np.dot(weights, returns)\n",
    "        p_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return - (p_return - risk_free_rate) / p_volatility\n",
    "    \n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for asset in range(num_assets))\n",
    "    \n",
    "    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets],\n",
    "                          method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    if save_weights:\n",
    "        return result.x\n",
    "    return result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Función para calcular el portafolio con máximo Sharpe (devuelve valores ponderados)\\ndef calculate_max_sharpe(prices, risk_free=0.05, save_weights=False):\\n    prices = prices.dropna()    \\n    mu = expected_returns.mean_historical_return(prices)\\n    S = risk_models.sample_cov(prices)\\n    ef = EfficientFrontier(mu, S)\\n    ef.max_sharpe(risk_free_rate=risk_free)\\n    weights = ef.clean_weights()\\n    if save_weights:\\n        return weights\\n    # Multiplica precios históricos por los pesos para obtener valores ponderados\\n    return prices.mul(weights, axis=1).sum(axis=1)\\n\\n# Función para calcular el portafolio de mínima volatilidad\\ndef calculate_min_volatility(prices, save_weights=False):\\n    prices = prices.dropna()    \\n    mu = expected_returns.mean_historical_return(prices)\\n    S = risk_models.sample_cov(prices)\\n    ef = EfficientFrontier(mu, S)\\n    ef.min_volatility()\\n    weights = ef.clean_weights()\\n    if save_weights:\\n        return weights\\n    # Multiplica precios históricos por los pesos para obtener valores ponderados\\n    return prices.mul(weights, axis=1).sum(axis=1)\\n\\n\\n# Función para calcular el portafolio de máximo rendimiento esperado\\ndef calculate_max_return(prices, save_weights=False):\\n    prices = prices.dropna()    \\n    mu = expected_returns.mean_historical_return(prices)\\n    S = risk_models.sample_cov(prices)\\n    ef = EfficientFrontier(mu, S)\\n    ef.max_quadratic_utility()\\n    weights = ef.clean_weights()\\n    if save_weights:\\n        return weights\\n    # Multiplica precios históricos por los pesos para obtener valores ponderados\\n    return prices.mul(weights, axis=1).sum(axis=1)\\n\\n# Funcion para calcular un portafolio de pesos iguales con pyportfolioopt\\ndef calculate_equal_weights(prices, save_weights=False):\\n    prices = prices.dropna()\\n    num_assets = len(prices.columns)\\n    # Calcular pesos iguales\\n    weight = 1.0 / num_assets\\n    weights = {asset: weight for asset in prices.columns}\\n    if save_weights:\\n        return weights\\n    return prices.mul(weights, axis=1).sum(axis=1)\\n\\n\\n# Funcion para calculrar portafolio con un riesgo fijo usando pyportfolioopt\\ndef calculate_risk_limit(prices, risk_limit=0.02, save_weights=False):\\n    prices = prices.dropna()    \\n    mu = expected_returns.mean_historical_return(prices)\\n    S = risk_models.sample_cov(prices)\\n    ef = EfficientFrontier(mu, S)\\n    ef.efficient_risk(risk_limit)\\n    weights = ef.clean_weights()\\n    if save_weights:\\n        return weights\\n    # Multiplica precios históricos por los pesos para obtener valores ponderados\\n    return prices.mul(weights, axis=1).sum(axis=1)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Función para calcular el portafolio con máximo Sharpe (devuelve valores ponderados)\n",
    "def calculate_max_sharpe(prices, risk_free=0.05, save_weights=False):\n",
    "    prices = prices.dropna()    \n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.max_sharpe(risk_free_rate=risk_free)\n",
    "    weights = ef.clean_weights()\n",
    "    if save_weights:\n",
    "        return weights\n",
    "    # Multiplica precios históricos por los pesos para obtener valores ponderados\n",
    "    return prices.mul(weights, axis=1).sum(axis=1)\n",
    "\n",
    "# Función para calcular el portafolio de mínima volatilidad\n",
    "def calculate_min_volatility(prices, save_weights=False):\n",
    "    prices = prices.dropna()    \n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.min_volatility()\n",
    "    weights = ef.clean_weights()\n",
    "    if save_weights:\n",
    "        return weights\n",
    "    # Multiplica precios históricos por los pesos para obtener valores ponderados\n",
    "    return prices.mul(weights, axis=1).sum(axis=1)\n",
    "\n",
    "\n",
    "# Función para calcular el portafolio de máximo rendimiento esperado\n",
    "def calculate_max_return(prices, save_weights=False):\n",
    "    prices = prices.dropna()    \n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.max_quadratic_utility()\n",
    "    weights = ef.clean_weights()\n",
    "    if save_weights:\n",
    "        return weights\n",
    "    # Multiplica precios históricos por los pesos para obtener valores ponderados\n",
    "    return prices.mul(weights, axis=1).sum(axis=1)\n",
    "\n",
    "# Funcion para calcular un portafolio de pesos iguales con pyportfolioopt\n",
    "def calculate_equal_weights(prices, save_weights=False):\n",
    "    prices = prices.dropna()\n",
    "    num_assets = len(prices.columns)\n",
    "    # Calcular pesos iguales\n",
    "    weight = 1.0 / num_assets\n",
    "    weights = {asset: weight for asset in prices.columns}\n",
    "    if save_weights:\n",
    "        return weights\n",
    "    return prices.mul(weights, axis=1).sum(axis=1)\n",
    "\n",
    "\n",
    "# Funcion para calculrar portafolio con un riesgo fijo usando pyportfolioopt\n",
    "def calculate_risk_limit(prices, risk_limit=0.02, save_weights=False):\n",
    "    prices = prices.dropna()    \n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.efficient_risk(risk_limit)\n",
    "    weights = ef.clean_weights()\n",
    "    if save_weights:\n",
    "        return weights\n",
    "    # Multiplica precios históricos por los pesos para obtener valores ponderados\n",
    "    return prices.mul(weights, axis=1).sum(axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Función para calcular y obtener métricas de portafolios específicos\\ndef calcular_portafolios_especificos(returns, risk_free=0.05, risk_limit=0.20):\\n    mu = expected_returns.mean_historical_return(returns)\\n    S = risk_models.sample_cov(returns)\\n    ef = EfficientFrontier(mu, S)\\n\\n    # Portafolio de máximo Sharpe\\n    ef.max_sharpe(risk_free_rate=risk_free)\\n    weights_sharpe = ef.clean_weights()\\n    performance_sharpe = ef.portfolio_performance(risk_free_rate=risk_free)\\n\\n    # Portafolio de mínima volatilidad\\n    ef_min_vol = EfficientFrontier(mu, S)\\n    ef_min_vol.min_volatility()\\n    weights_min_vol = ef_min_vol.clean_weights()\\n    performance_min_vol = ef_min_vol.portfolio_performance()\\n\\n    # Portafolio de pesos iguales\\n    n_assets = len(mu)\\n    weights_equal = np.array([1/n_assets] * n_assets)\\n    ret_equal = np.dot(weights_equal, mu)\\n    vol_equal = np.sqrt(np.dot(weights_equal.T, np.dot(S, weights_equal)))\\n    sharpe_equal = (ret_equal - risk_free) / vol_equal\\n    performance_equal = (ret_equal, vol_equal, sharpe_equal)\\n    \\n    # Portafolio de máxima utilidad cuadrática\\n    ef_max_utility = EfficientFrontier(mu, S)\\n    ef_max_utility.max_quadratic_utility()\\n    weights_max_utility = ef_max_utility.clean_weights()\\n    performance_max_utility = ef_max_utility.portfolio_performance()\\n\\n    # Portafolio de riesgo fijo\\n    ef_risk_limit = EfficientFrontier(mu, S)\\n    ef_risk_limit.efficient_risk(risk_limit)\\n    weights_risk_limit = ef_risk_limit.clean_weights()\\n    performance_risk_limit = ef_risk_limit.portfolio_performance()\\n    \\n    # Métricas de los activos individuales\\n    performance_activos = []\\n    for i, asset in enumerate(returns.columns):\\n        weights_asset = np.zeros(n_assets)\\n        weights_asset[i] = 1\\n        ret_asset = np.dot(weights_asset, mu)\\n        vol_asset = np.sqrt(np.dot(weights_asset.T, np.dot(S, weights_asset)))\\n        sharpe_asset = (ret_asset - risk_free) / vol_asset\\n        performance_activos.append((asset, ret_asset, vol_asset, sharpe_asset))\\n\\n    return {\\n        \"sharpe\": {\"weights\": weights_sharpe, \"performance\": performance_sharpe},\\n        \"min_vol\": {\"weights\": weights_min_vol, \"performance\": performance_min_vol},\\n        \"equal\": {\"weights\": weights_equal, \"performance\": performance_equal},\\n        \"max_utility\": {\"weights\": weights_max_utility, \"performance\": performance_max_utility},\\n        \"risk_limit\": {\"weights\": weights_risk_limit, \"performance\": performance_risk_limit},\\n        \"activos\": performance_activos\\n    }\\n\\n    # Función para calcular las métricas de los portafolios generados aleatoriamente\\ndef calcular_metricas_aleatorias(portfolios, mu, S, risk_free=0.05):\\n    expected_returns_all = portfolios.dot(mu)\\n    portfolio_volatility = np.sqrt(np.diag(portfolios.dot(S).dot(portfolios.T)))\\n    sharpe_ratios = (expected_returns_all - risk_free) / portfolio_volatility\\n    return expected_returns_all, portfolio_volatility, sharpe_ratios\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def calculate_max_sharpe(prices, risk_free=0.05, save_weights=False, index_calcs=False):\n",
    "    prices = prices.dropna()\n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.max_sharpe(risk_free_rate=risk_free)\n",
    "    weights = ef.clean_weights()\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_min_volatility(prices, risk_free=0.05, save_weights=False, index_calcs=False):\n",
    "    prices = prices.dropna()\n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.min_volatility()\n",
    "    weights = ef.clean_weights()\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_max_return(prices, risk_free=0.05, save_weights=False, index_calcs=False):\n",
    "    prices = prices.dropna()\n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.max_quadratic_utility()\n",
    "    weights = ef.clean_weights()\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_equal_weights(prices, risk_free=0.05, save_weights=False, index_calcs=False):\n",
    "    prices = prices.dropna()\n",
    "    num_assets = len(prices.columns)\n",
    "    weights = {asset: 1.0 / num_assets for asset in prices.columns}\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_risk_limit(prices, risk_free=0.05, risk_limit=0.20, save_weights=False, index_calcs=False):\n",
    "    prices = prices.dropna()\n",
    "    mu = expected_returns.mean_historical_return(prices)\n",
    "    S = risk_models.sample_cov(prices)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.efficient_risk(risk_limit)\n",
    "    weights = ef.clean_weights()\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Función para calcular y obtener métricas de portafolios específicos\n",
    "def calcular_portafolios_especificos(returns, risk_free=0.05, risk_limit=0.20):\n",
    "    mu = expected_returns.mean_historical_return(returns)\n",
    "    S = risk_models.sample_cov(returns)\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "\n",
    "    # Portafolio de máximo Sharpe\n",
    "    ef.max_sharpe(risk_free_rate=risk_free)\n",
    "    weights_sharpe = ef.clean_weights()\n",
    "    performance_sharpe = ef.portfolio_performance(risk_free_rate=risk_free)\n",
    "\n",
    "    # Portafolio de mínima volatilidad\n",
    "    ef_min_vol = EfficientFrontier(mu, S)\n",
    "    ef_min_vol.min_volatility()\n",
    "    weights_min_vol = ef_min_vol.clean_weights()\n",
    "    performance_min_vol = ef_min_vol.portfolio_performance()\n",
    "\n",
    "    # Portafolio de pesos iguales\n",
    "    n_assets = len(mu)\n",
    "    weights_equal = np.array([1/n_assets] * n_assets)\n",
    "    ret_equal = np.dot(weights_equal, mu)\n",
    "    vol_equal = np.sqrt(np.dot(weights_equal.T, np.dot(S, weights_equal)))\n",
    "    sharpe_equal = (ret_equal - risk_free) / vol_equal\n",
    "    performance_equal = (ret_equal, vol_equal, sharpe_equal)\n",
    "    \n",
    "    # Portafolio de máxima utilidad cuadrática\n",
    "    ef_max_utility = EfficientFrontier(mu, S)\n",
    "    ef_max_utility.max_quadratic_utility()\n",
    "    weights_max_utility = ef_max_utility.clean_weights()\n",
    "    performance_max_utility = ef_max_utility.portfolio_performance()\n",
    "\n",
    "    # Portafolio de riesgo fijo\n",
    "    ef_risk_limit = EfficientFrontier(mu, S)\n",
    "    ef_risk_limit.efficient_risk(risk_limit)\n",
    "    weights_risk_limit = ef_risk_limit.clean_weights()\n",
    "    performance_risk_limit = ef_risk_limit.portfolio_performance()\n",
    "    \n",
    "    # Métricas de los activos individuales\n",
    "    performance_activos = []\n",
    "    for i, asset in enumerate(returns.columns):\n",
    "        weights_asset = np.zeros(n_assets)\n",
    "        weights_asset[i] = 1\n",
    "        ret_asset = np.dot(weights_asset, mu)\n",
    "        vol_asset = np.sqrt(np.dot(weights_asset.T, np.dot(S, weights_asset)))\n",
    "        sharpe_asset = (ret_asset - risk_free) / vol_asset\n",
    "        performance_activos.append((asset, ret_asset, vol_asset, sharpe_asset))\n",
    "\n",
    "    return {\n",
    "        \"sharpe\": {\"weights\": weights_sharpe, \"performance\": performance_sharpe},\n",
    "        \"min_vol\": {\"weights\": weights_min_vol, \"performance\": performance_min_vol},\n",
    "        \"equal\": {\"weights\": weights_equal, \"performance\": performance_equal},\n",
    "        \"max_utility\": {\"weights\": weights_max_utility, \"performance\": performance_max_utility},\n",
    "        \"risk_limit\": {\"weights\": weights_risk_limit, \"performance\": performance_risk_limit},\n",
    "        \"activos\": performance_activos\n",
    "    }\n",
    "\n",
    "    # Función para calcular las métricas de los portafolios generados aleatoriamente\n",
    "def calcular_metricas_aleatorias(portfolios, mu, S, risk_free=0.05):\n",
    "    expected_returns_all = portfolios.dot(mu)\n",
    "    portfolio_volatility = np.sqrt(np.diag(portfolios.dot(S).dot(portfolios.T)))\n",
    "    sharpe_ratios = (expected_returns_all - risk_free) / portfolio_volatility\n",
    "    return expected_returns_all, portfolio_volatility, sharpe_ratios\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Portafolios y metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max_sharpe(prices, risk_free=0.05, min_weight=0, save_weights=False, index_calcs=False, use_returns=False):\n",
    "    prices = prices.dropna()\n",
    "    if use_returns == False:\n",
    "        mu = expected_returns.mean_historical_return(prices)\n",
    "        S = risk_models.sample_cov(prices)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices.pct_change().dropna()\n",
    "    else:\n",
    "        mu = expected_returns.mean_historical_return(prices, returns_data=True)\n",
    "        S = risk_models.sample_cov(prices, returns_data=True)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices\n",
    "    \n",
    "    ef.max_sharpe(risk_free_rate=risk_free)\n",
    "    weights = ef.clean_weights()\n",
    "    \n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    \n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_min_volatility(prices, risk_free=0.05, min_weight=0, save_weights=False, index_calcs=False, use_returns=False):\n",
    "    prices = prices.dropna()\n",
    "    if use_returns == False:\n",
    "        mu = expected_returns.mean_historical_return(prices)\n",
    "        S = risk_models.sample_cov(prices)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices.pct_change().dropna()\n",
    "    else:\n",
    "        mu = expected_returns.mean_historical_return(prices, returns_data=True)\n",
    "        S = risk_models.sample_cov(prices, returns_data=True)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices\n",
    "\n",
    "    ef.min_volatility()\n",
    "    weights = ef.clean_weights()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    \n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_max_return(prices, risk_free=0.05, min_weight=0, save_weights=False, index_calcs=False, use_returns=False):\n",
    "    prices = prices.dropna()\n",
    "    if use_returns == False:\n",
    "        mu = expected_returns.mean_historical_return(prices)\n",
    "        S = risk_models.sample_cov(prices)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices.pct_change().dropna()\n",
    "    else:\n",
    "        mu = expected_returns.mean_historical_return(prices, returns_data=True)\n",
    "        S = risk_models.sample_cov(prices, returns_data=True)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices\n",
    "    \n",
    "    ef.max_quadratic_utility()\n",
    "    weights = ef.clean_weights()\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    \n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_equal_weights(prices, risk_free=0.05, save_weights=False, index_calcs=False):\n",
    "    prices = prices.dropna()\n",
    "    num_assets = len(prices.columns)\n",
    "    weights = {asset: 1.0 / num_assets for asset in prices.columns}\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "def calculate_risk_limit(prices, risk_free=0.05, risk_limit=0.20, min_weight=0, save_weights=False, index_calcs=False, use_returns=False):\n",
    "    prices = prices.dropna()\n",
    "    if use_returns == False:\n",
    "        mu = expected_returns.mean_historical_return(prices)\n",
    "        S = risk_models.sample_cov(prices)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices.pct_change().dropna()\n",
    "    else:\n",
    "        mu = expected_returns.mean_historical_return(prices, returns_data=True)\n",
    "        S = risk_models.sample_cov(prices, returns_data=True)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        if min_weight > 0:\n",
    "            ef.add_constraint(lambda w: w >= min_weight)\n",
    "        returns = prices\n",
    "    \n",
    "    ef.efficient_risk(risk_limit)\n",
    "    weights = ef.clean_weights()\n",
    "    returns = prices.pct_change().dropna()\n",
    "    portfolio_returns = returns.dot(pd.Series(weights))\n",
    "    \n",
    "    if index_calcs:\n",
    "        metrics = calculate_metrics(portfolio_returns, prices.index, risk_free)\n",
    "        return metrics\n",
    "    \n",
    "    if save_weights:\n",
    "        return weights\n",
    "\n",
    "    return portfolio_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para calcular todos los indicadores\n",
    "def calculate_metrics(returns, date_index, risk_free):\n",
    "    cumulative_return = (returns + 1).cumprod() - 1\n",
    "    cumulative_return = cumulative_return.iloc[-1]\n",
    "    cagr = calculate_cagr(returns)\n",
    "    volatility = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (returns.mean() * 252 - risk_free) / volatility\n",
    "    sortino_ratio = calculate_sortino(returns, risk_free)\n",
    "    omega_ratio = calculate_omega(returns, risk_free)\n",
    "    max_drawdown = calculate_max_drawdown(returns)\n",
    "    max_drawdown_duration = calculate_drawdown_duration(returns)\n",
    "\n",
    "    return {\n",
    "        \"start_period\": date_index[0].strftime(\"%Y-%m-%d\"),\n",
    "        \"end_period\": date_index[-1].strftime(\"%Y-%m-%d\"),\n",
    "        \"risk_free_rate %\": risk_free * 100,\n",
    "        \"expected_return %\": (returns.mean() * 252)*100,\n",
    "        \"volatility %\": volatility*100,\n",
    "        \"cumulative_return %\": cumulative_return*100,\n",
    "        \"cagr %\": cagr*100,\n",
    "        \"sharpe_ratio\": sharpe_ratio,\n",
    "        \"sortino_ratio\": sortino_ratio,\n",
    "        \"omega_ratio\": omega_ratio,\n",
    "        \"max_drawdown\": max_drawdown*100,\n",
    "        \"max_drawdown_duration\": max_drawdown_duration\n",
    "    }\n",
    "\n",
    "def calculate_cagr(returns):\n",
    "    n_periods = len(returns) / 252\n",
    "    cumulative_return = (returns + 1).cumprod() - 1\n",
    "    cumulative_return = cumulative_return.iloc[-1]\n",
    "    return ((1 + cumulative_return) ** (1 / n_periods) - 1)\n",
    "\n",
    "def calculate_sortino(returns, risk_free):\n",
    "    downside_returns = returns[returns < risk_free / 252]\n",
    "    expected_return = returns.mean() * 252\n",
    "    downside_deviation = np.std(downside_returns) * np.sqrt(252)\n",
    "    return (expected_return - risk_free) / downside_deviation\n",
    "\n",
    "def calculate_omega(returns, risk_free):\n",
    "    threshold_return = risk_free / 252\n",
    "    gain = returns[returns > threshold_return].sum()\n",
    "    loss = -returns[returns <= threshold_return].sum()\n",
    "    return gain / loss if loss != 0 else np.inf\n",
    "\n",
    "def calculate_max_drawdown(returns):\n",
    "    cumulative_returns = (1 + returns).cumprod()\n",
    "    peak = cumulative_returns.cummax()\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "    return drawdown.min()\n",
    "\n",
    "def calculate_drawdown_duration(returns):\n",
    "    cumulative_returns = (1 + returns).cumprod()\n",
    "    peak = cumulative_returns.cummax()\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "    in_drawdown = drawdown != 0\n",
    "    drawdown_duration = in_drawdown.groupby((in_drawdown != in_drawdown.shift()).cumsum()).cumsum()\n",
    "    return drawdown_duration.max()\n",
    "\n",
    "# Función para calcular las métricas para todos los portafolios y activos\n",
    "def calculate_indicators_for_all_portfolios(prices, risk_free=0.05, risk_limit=0.2, min_weight=0,include_assets=False):\n",
    "    portafolios = {\n",
    "        \"Max_Sharpe\": calculate_max_sharpe(prices, risk_free=risk_free, min_weight=min_weight, index_calcs=True),\n",
    "        \"Min_Volatility\": calculate_min_volatility(prices, risk_free=risk_free, min_weight=min_weight, index_calcs=True),\n",
    "        \"Max_Return\": calculate_max_return(prices, risk_free=risk_free, min_weight=min_weight, index_calcs=True),\n",
    "        \"Equal_Weight\": calculate_equal_weights(prices, risk_free=risk_free, index_calcs=True),\n",
    "        \"Risk_Limit\": calculate_risk_limit(prices, risk_limit=risk_limit,risk_free=risk_free, min_weight=min_weight, index_calcs=True)\n",
    "    }\n",
    "    \n",
    "    if include_assets:\n",
    "        asset_indicators = {}\n",
    "        for asset in prices.columns:\n",
    "            asset_returns = prices[asset].pct_change().dropna()\n",
    "            asset_indicators[asset] = calculate_metrics(asset_returns, prices.index, risk_free)\n",
    "        portafolios.update(asset_indicators)\n",
    "\n",
    "    df_indicators = pd.DataFrame(portafolios)\n",
    "    return df_indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Portfolio generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para agregar activos y portafolios a un solo DataFrame\n",
    "def generate_portfolio_df(data, use_returns=False, include_sharpe=True, include_min_vol=True, include_max_return=True, include_equal_weight=True, include_risk_limit=True, risk_free=0.05, risk_limit=0.02, min_weight=0, include_assets=False, save_weights=False):\n",
    "    # Crear una copia del DataFrame original\n",
    "    portfolio_df = data.copy().pct_change().dropna()\n",
    "\n",
    "    # Calcular y añadir las estrategias seleccionadas al DataFrame\n",
    "    if include_sharpe:\n",
    "        portfolio_df['Max_Sharpe'] = calculate_max_sharpe(data, risk_free=risk_free, min_weight=min_weight, save_weights=save_weights, use_returns=use_returns)\n",
    "    if include_min_vol:\n",
    "        portfolio_df['Min_Volatility'] = calculate_min_volatility(data, min_weight=min_weight, save_weights=save_weights, use_returns=use_returns)\n",
    "    if include_max_return:\n",
    "        portfolio_df['Max_Return'] = calculate_max_return(data, min_weight=min_weight, save_weights=save_weights, use_returns=use_returns)\n",
    "    if include_equal_weight:\n",
    "        portfolio_df['Equal_Weight'] = calculate_equal_weights(data, save_weights=save_weights)\n",
    "    if include_risk_limit:\n",
    "        #portfolio_df['Risk_Limit'] = calculate_risk_limit(data, risk_limit=risk_limit, save_weights=save_weights)\n",
    "        portfolio_df['Risk_Limit'] = calculate_risk_limit(data, risk_limit=risk_limit, min_weight=min_weight, save_weights=save_weights, use_returns=use_returns)\n",
    "# para hacer que solo regrese los portafolios y no los activos se usa el siguiente codigo\n",
    "#     # Eliminar las columnas de activos\n",
    "    if not include_assets:\n",
    "        portfolio_df = portfolio_df.drop(data.columns, axis=1)\n",
    "    return portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Add cripto to portafolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para agregar criptos a portafolios tradicionales\n",
    "def add_cripto(tradicionales, cripto, cry_list):\n",
    "    # Asegurarse de que ambos DataFrames tengan índices de tipo datetime\n",
    "    tradicionales.index = pd.to_datetime(tradicionales.index)\n",
    "    cripto.index = pd.to_datetime(cripto.index)\n",
    "    \n",
    "    # añadir un try para evitar errores\n",
    "    try:\n",
    "        # Verificar que las criptomonedas seleccionadas existan en el DataFrame\n",
    "        cry_list = [crypto for crypto in cry_list if crypto in cripto.columns]\n",
    "    except:\n",
    "        print('Error: cripto no es un DataFrame')\n",
    "    # Verificar que las criptomonedas seleccionadas existan en el DataFrame\n",
    "    \n",
    "    # Seleccionar solo las criptomonedas de la lista\n",
    "    criptos_seleccionadas = cripto[cry_list]\n",
    "    \n",
    "    # Combinar los DataFrames, alineando por fecha\n",
    "    combinado = pd.merge(tradicionales, criptos_seleccionadas, left_index=True, right_index=True, how='inner').dropna()\n",
    "    \n",
    "    return combinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Frontera Eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular y obtener métricas de portafolios específicos\n",
    "def calcular_portafolios_especificos(returns, risk_free=0.05, risk_limit=0.20, min_weight=0):\n",
    "    mu = expected_returns.mean_historical_return(returns)\n",
    "    S = risk_models.sample_cov(returns)\n",
    "\n",
    "    # Portafolio de máximo Sharpe\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    if min_weight > 0:\n",
    "        ef.add_constraint(lambda w: w >= min_weight)\n",
    "    ef.max_sharpe(risk_free_rate=risk_free)\n",
    "    weights_sharpe = ef.clean_weights()\n",
    "    performance_sharpe = ef.portfolio_performance(risk_free_rate=risk_free)\n",
    "\n",
    "    # Portafolio de mínima volatilidad\n",
    "    ef_min_vol = EfficientFrontier(mu, S)\n",
    "    if min_weight > 0:\n",
    "        ef_min_vol.add_constraint(lambda w: w >= min_weight)\n",
    "    ef_min_vol.min_volatility()\n",
    "    weights_min_vol = ef_min_vol.clean_weights()\n",
    "    performance_min_vol = ef_min_vol.portfolio_performance()\n",
    "\n",
    "    # Portafolio de pesos iguales\n",
    "    n_assets = len(mu)\n",
    "    weights_equal = np.array([max(min_weight, 1/n_assets)] * n_assets)\n",
    "    if sum(weights_equal) < 1:\n",
    "        weights_equal *= 1 / sum(weights_equal)\n",
    "    ret_equal = np.dot(weights_equal, mu)\n",
    "    vol_equal = np.sqrt(np.dot(weights_equal.T, np.dot(S, weights_equal)))\n",
    "    sharpe_equal = (ret_equal - risk_free) / vol_equal\n",
    "    performance_equal = (ret_equal, vol_equal, sharpe_equal)\n",
    "    \n",
    "    # Portafolio de máxima utilidad cuadrática\n",
    "    ef_max_utility = EfficientFrontier(mu, S)\n",
    "    if min_weight > 0:\n",
    "        ef_max_utility.add_constraint(lambda w: w >= min_weight)\n",
    "    ef_max_utility.max_quadratic_utility()\n",
    "    weights_max_utility = ef_max_utility.clean_weights()\n",
    "    performance_max_utility = ef_max_utility.portfolio_performance()\n",
    "\n",
    "    # Portafolio de riesgo fijo\n",
    "    ef_risk_limit = EfficientFrontier(mu, S)\n",
    "    if min_weight > 0:\n",
    "        ef_risk_limit.add_constraint(lambda w: w >= min_weight)\n",
    "    ef_risk_limit.efficient_risk(risk_limit)\n",
    "    weights_risk_limit = ef_risk_limit.clean_weights()\n",
    "    performance_risk_limit = ef_risk_limit.portfolio_performance()\n",
    "    \n",
    "    # Métricas de los activos individuales\n",
    "    performance_activos = []\n",
    "    for i, asset in enumerate(returns.columns):\n",
    "        weights_asset = np.zeros(n_assets)\n",
    "        weights_asset[i] = 1\n",
    "        ret_asset = np.dot(weights_asset, mu)\n",
    "        vol_asset = np.sqrt(np.dot(weights_asset.T, np.dot(S, weights_asset)))\n",
    "        sharpe_asset = (ret_asset - risk_free) / vol_asset\n",
    "        performance_activos.append((asset, ret_asset, vol_asset, sharpe_asset))\n",
    "\n",
    "    return {\n",
    "        \"sharpe\": {\"weights\": weights_sharpe, \"performance\": performance_sharpe},\n",
    "        \"min_vol\": {\"weights\": weights_min_vol, \"performance\": performance_min_vol},\n",
    "        \"equal\": {\"weights\": weights_equal, \"performance\": performance_equal},\n",
    "        \"max_utility\": {\"weights\": weights_max_utility, \"performance\": performance_max_utility},\n",
    "        \"risk_limit\": {\"weights\": weights_risk_limit, \"performance\": performance_risk_limit},\n",
    "        \"activos\": performance_activos\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Función para graficar la frontera eficiente y los portafolios específicos\\ndef graficar_frontera_eficiente(data, iteraciones=10000, risk_free=0.05, min_weight=0.01, risk_limit=0.20, title=\\'Portafolio\\'):\\n    data = data.dropna()\\n    activos = data.columns.tolist()\\n    portfolios = weight_portfolios(activos, iteraciones, min_weight=min_weight)\\n\\n    mu = expected_returns.mean_historical_return(data)\\n    S = risk_models.sample_cov(data)\\n\\n    expected_returns_all, portfolio_volatility, sharpe_ratios = calcular_metricas_aleatorias(portfolios, mu, S, risk_free)\\n\\n    # Calcular portafolios específicos\\n    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit)\\n    \\n    # Preparar datos para la gráfica\\n    rendimiento_sharpe = portafolios_especificos[\"sharpe\"][\"performance\"][0]\\n    riesgo_sharpe = portafolios_especificos[\"sharpe\"][\"performance\"][1]\\n    # Calcular sharpe de maximo sharpe portafolio\\n    sharpe_sharpe = (rendimiento_sharpe - risk_free) / riesgo_sharpe\\n\\n    rendimiento_min_var = portafolios_especificos[\"min_vol\"][\"performance\"][0]\\n    riesgo_min_var = portafolios_especificos[\"min_vol\"][\"performance\"][1]\\n    \\n    rendimiento_max_utility = portafolios_especificos[\"max_utility\"][\"performance\"][0]\\n    riesgo_max_utility = portafolios_especificos[\"max_utility\"][\"performance\"][1]\\n\\n    rendimiento_igual = portafolios_especificos[\"equal\"][\"performance\"][0]\\n    riesgo_igual = portafolios_especificos[\"equal\"][\"performance\"][1]\\n\\n    rendimiento_risk_limit = portafolios_especificos[\"risk_limit\"][\"performance\"][0]\\n    riesgo_risk_limit = portafolios_especificos[\"risk_limit\"][\"performance\"][1]\\n\\n    # Graficar\\n    plt.figure(figsize=(12, 8))\\n    plt.scatter(portfolio_volatility, expected_returns_all*100, c=sharpe_ratios, cmap=\\'viridis\\', alpha=0.5)\\n    plt.colorbar(label=\\'Ratio de Sharpe\\', pad=0.1) \\n\\n    # Mejorar el estilo de la gráfica\\n    plt.xlabel(\\'Volatilidad (Riesgo del Portafolio)\\', fontsize=12, fontweight=\\'bold\\')\\n    plt.ylabel(\\'Rendimiento Esperado del Portafolio % (anual)\\', fontsize=12, fontweight=\\'bold\\')\\n    plt.suptitle(title, fontsize=18, fontweight=\\'bold\\')\\n    plt.title(\\'Gráfica de Dispersión: Rendimiento vs. Volatilidad\\', fontsize=12, fontweight=\\'bold\\')\\n    plt.grid(True, linestyle=\\'--\\', alpha=0.5)\\n    plt.tick_params(axis=\\'both\\', which=\\'major\\', labelsize=10)\\n\\n    # Añadir el punto del portafolio de mínima varianza en rojo\\n    plt.scatter(riesgo_min_var, rendimiento_min_var*100, color=\\'#FF3030\\', s=150, marker=\\'*\\', edgecolors=\\'#1A1A1A\\', linewidth=0.8, label=\\'Portafolio de Mínima Varianza\\')\\n\\n    # Añadir el punto del portafolio de pesos iguales en morado\\n    plt.scatter(riesgo_igual, rendimiento_igual*100, color=\\'#8B008B\\', s=150, marker=\\'*\\', edgecolors=\\'#1A1A1A\\', linewidth=0.8, label=\\'Portafolio Equal Weight\\')\\n\\n    # Añadir el punto del portafolio de máximo Sharpe en azul\\n    plt.scatter(riesgo_sharpe, rendimiento_sharpe*100, color=\\'#00FFFF\\', s=150, marker=\\'*\\', edgecolors=\\'#1A1A1A\\', linewidth=0.8, label=\\'Portafolio de Máximo Sharpe\\')\\n    \\n    # Añadir el punto del portafolio de máxima utilidad cuadrática en verde\\n    plt.scatter(riesgo_max_utility, rendimiento_max_utility*100, color=\\'#76EE00\\', s=150, marker=\\'*\\', edgecolors=\\'#1A1A1A\\', linewidth=0.8, label=\\'Portafolio de Máxima Utilidad Cuadrática\\')\\n\\n    # Añadir el punto del portafolio de riesgo fijo en naranja\\n    plt.scatter(riesgo_risk_limit, rendimiento_risk_limit*100, color=\\'#FFD700\\', s=150, marker=\\'*\\', edgecolors=\\'#1A1A1A\\', linewidth=0.8, label=\\'Portafolio de Riesgo Fijo\\')\\n\\n    # Añadir los puntos de los activos individuales con etiquetas en la gráfica\\n    for (asset, ret_asset, vol_asset, sharpe_asset) in portafolios_especificos[\"activos\"]:\\n        plt.scatter(vol_asset, ret_asset*100, marker=\\'o\\', s=35, edgecolors=\\'black\\', facecolors=\\'none\\')\\n        #plt.text(vol_asset, (ret_asset*100), asset, fontsize=8, fontweight=\\'bold\\', ha=\\'center\\', color=\\'#0A0A0A\\')\\n\\n    plt.legend(loc=\\'upper left\\', fontsize=10, bbox_to_anchor=(0.01, 0.99)) \\n    plt.text(0.5, 0.96, f\\'Tasa libre de riesgo: {risk_free*100:.2f}%\\', transform=plt.gca().transAxes, fontsize=10,fontweight=\\'bold\\', color=\\'#363636\\')\\n    # Añadir otro texto que muestre el ratio sharpe mas grande y el portafoio al que pertenece\\n    plt.text(0.5, 0.93, f\\'Mejor Ratio de Sharpe: {sharpe_sharpe:.2f}\\', transform=plt.gca().transAxes, fontsize=10,fontweight=\\'bold\\', color=\\'#363636\\')\\n    # Añadir texto con minimo riesgo, y maximo rendimiento\\n    #plt.text(0.5, 0.90, f\\'Riesgo Mínimo: {riesgo_min_var*100:.2f}%\\', transform=plt.gca().transAxes, fontsize=10,fontweight=\\'bold\\', color=\\'#363636\\')\\n    # Texto con pesos de portafolio maximo sharpe\\n    #weights_sharpe = portafolios_especificos[\"sharpe\"][\"weights\"]\\n    #texto_pesos_sharpe = f\\'Pesos del Portafolio de Máximo Sharpe:\\n{weights_sharpe}\\'\\n    #plt.text(0.1, 0.05, texto_pesos_sharpe, transform=plt.gca().transAxes, fontsize=10, fontweight=\\'bold\\', color=\\'#363636\\')\\n    \\n    \\n    #plt.text(0.5, 0.87, f\\'Rendimiento Máximo: {rendimiento_max_utility*100:.2f}%\\', transform=plt.gca().transAxes, fontsize=10,fontweight=\\'bold\\', color=\\'#363636\\')\\n\\n    plt.show()\\n    \\n    '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para generar combinaciones aleatorias de portafolios\n",
    "def weight_portfolios(activos, iteraciones=10000, min_weight=0.0):\n",
    "    max_weight = 1 - (len(activos) * min_weight)\n",
    "    portfolios = []\n",
    "    for _ in range(iteraciones):\n",
    "        weights = np.random.dirichlet(np.ones(len(activos)), size=1)[0]\n",
    "        weights = np.clip(weights, min_weight, max_weight)\n",
    "        portfolios.append(weights)\n",
    "    portfolios = pd.DataFrame(portfolios, columns=activos)\n",
    "    return portfolios\n",
    "# Función para calcular las métricas de los portafolios generados aleatoriamente\n",
    "def calcular_metricas_aleatorias(portfolios, mu, S, risk_free=0.05):\n",
    "    expected_returns_all = portfolios.dot(mu)\n",
    "    portfolio_volatility = np.sqrt(np.diag(portfolios.dot(S).dot(portfolios.T)))\n",
    "    sharpe_ratios = (expected_returns_all - risk_free) / portfolio_volatility\n",
    "    return expected_returns_all, portfolio_volatility, sharpe_ratios\n",
    "\n",
    "\"\"\"\n",
    "# Función para graficar la frontera eficiente y los portafolios específicos\n",
    "def graficar_frontera_eficiente(data, iteraciones=10000, risk_free=0.05, min_weight=0.01, risk_limit=0.20, title='Portafolio'):\n",
    "    data = data.dropna()\n",
    "    activos = data.columns.tolist()\n",
    "    portfolios = weight_portfolios(activos, iteraciones, min_weight=min_weight)\n",
    "\n",
    "    mu = expected_returns.mean_historical_return(data)\n",
    "    S = risk_models.sample_cov(data)\n",
    "\n",
    "    expected_returns_all, portfolio_volatility, sharpe_ratios = calcular_metricas_aleatorias(portfolios, mu, S, risk_free)\n",
    "\n",
    "    # Calcular portafolios específicos\n",
    "    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit)\n",
    "    \n",
    "    # Preparar datos para la gráfica\n",
    "    rendimiento_sharpe = portafolios_especificos[\"sharpe\"][\"performance\"][0]\n",
    "    riesgo_sharpe = portafolios_especificos[\"sharpe\"][\"performance\"][1]\n",
    "    # Calcular sharpe de maximo sharpe portafolio\n",
    "    sharpe_sharpe = (rendimiento_sharpe - risk_free) / riesgo_sharpe\n",
    "\n",
    "    rendimiento_min_var = portafolios_especificos[\"min_vol\"][\"performance\"][0]\n",
    "    riesgo_min_var = portafolios_especificos[\"min_vol\"][\"performance\"][1]\n",
    "    \n",
    "    rendimiento_max_utility = portafolios_especificos[\"max_utility\"][\"performance\"][0]\n",
    "    riesgo_max_utility = portafolios_especificos[\"max_utility\"][\"performance\"][1]\n",
    "\n",
    "    rendimiento_igual = portafolios_especificos[\"equal\"][\"performance\"][0]\n",
    "    riesgo_igual = portafolios_especificos[\"equal\"][\"performance\"][1]\n",
    "\n",
    "    rendimiento_risk_limit = portafolios_especificos[\"risk_limit\"][\"performance\"][0]\n",
    "    riesgo_risk_limit = portafolios_especificos[\"risk_limit\"][\"performance\"][1]\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(portfolio_volatility, expected_returns_all*100, c=sharpe_ratios, cmap='viridis', alpha=0.5)\n",
    "    plt.colorbar(label='Ratio de Sharpe', pad=0.1) \n",
    "\n",
    "    # Mejorar el estilo de la gráfica\n",
    "    plt.xlabel('Volatilidad (Riesgo del Portafolio)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Rendimiento Esperado del Portafolio % (anual)', fontsize=12, fontweight='bold')\n",
    "    plt.suptitle(title, fontsize=18, fontweight='bold')\n",
    "    plt.title('Gráfica de Dispersión: Rendimiento vs. Volatilidad', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    # Añadir el punto del portafolio de mínima varianza en rojo\n",
    "    plt.scatter(riesgo_min_var, rendimiento_min_var*100, color='#FF3030', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Mínima Varianza')\n",
    "\n",
    "    # Añadir el punto del portafolio de pesos iguales en morado\n",
    "    plt.scatter(riesgo_igual, rendimiento_igual*100, color='#8B008B', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio Equal Weight')\n",
    "\n",
    "    # Añadir el punto del portafolio de máximo Sharpe en azul\n",
    "    plt.scatter(riesgo_sharpe, rendimiento_sharpe*100, color='#00FFFF', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Máximo Sharpe')\n",
    "    \n",
    "    # Añadir el punto del portafolio de máxima utilidad cuadrática en verde\n",
    "    plt.scatter(riesgo_max_utility, rendimiento_max_utility*100, color='#76EE00', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Máxima Utilidad Cuadrática')\n",
    "\n",
    "    # Añadir el punto del portafolio de riesgo fijo en naranja\n",
    "    plt.scatter(riesgo_risk_limit, rendimiento_risk_limit*100, color='#FFD700', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Riesgo Fijo')\n",
    "\n",
    "    # Añadir los puntos de los activos individuales con etiquetas en la gráfica\n",
    "    for (asset, ret_asset, vol_asset, sharpe_asset) in portafolios_especificos[\"activos\"]:\n",
    "        plt.scatter(vol_asset, ret_asset*100, marker='o', s=35, edgecolors='black', facecolors='none')\n",
    "        #plt.text(vol_asset, (ret_asset*100), asset, fontsize=8, fontweight='bold', ha='center', color='#0A0A0A')\n",
    "\n",
    "    plt.legend(loc='upper left', fontsize=10, bbox_to_anchor=(0.01, 0.99)) \n",
    "    plt.text(0.5, 0.96, f'Tasa libre de riesgo: {risk_free*100:.2f}%', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "    # Añadir otro texto que muestre el ratio sharpe mas grande y el portafoio al que pertenece\n",
    "    plt.text(0.5, 0.93, f'Mejor Ratio de Sharpe: {sharpe_sharpe:.2f}', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "    # Añadir texto con minimo riesgo, y maximo rendimiento\n",
    "    #plt.text(0.5, 0.90, f'Riesgo Mínimo: {riesgo_min_var*100:.2f}%', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "    # Texto con pesos de portafolio maximo sharpe\n",
    "    #weights_sharpe = portafolios_especificos[\"sharpe\"][\"weights\"]\n",
    "    #texto_pesos_sharpe = f'Pesos del Portafolio de Máximo Sharpe:\\n{weights_sharpe}'\n",
    "    #plt.text(0.1, 0.05, texto_pesos_sharpe, transform=plt.gca().transAxes, fontsize=10, fontweight='bold', color='#363636')\n",
    "    \n",
    "    \n",
    "    #plt.text(0.5, 0.87, f'Rendimiento Máximo: {rendimiento_max_utility*100:.2f}%', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar la frontera eficiente y los portafolios específicos\n",
    "def graficar_frontera_eficiente(data, iteraciones=10000, risk_free=0.05, min_weight=0.0, risk_limit=0.20, title='Portafolio'):\n",
    "    data = data.dropna()\n",
    "    activos = data.columns.tolist()\n",
    "    portfolios = weight_portfolios(activos, iteraciones, min_weight=min_weight)\n",
    "\n",
    "    mu = expected_returns.mean_historical_return(data)\n",
    "    S = risk_models.sample_cov(data)\n",
    "\n",
    "    expected_returns_all, portfolio_volatility, sharpe_ratios = calcular_metricas_aleatorias(portfolios, mu, S, risk_free)\n",
    "\n",
    "    # Calcular portafolios específicos\n",
    "    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit, min_weight=min_weight)\n",
    "    \n",
    "    # Preparar datos para la gráfica\n",
    "    rendimiento_sharpe = portafolios_especificos[\"sharpe\"][\"performance\"][0]\n",
    "    riesgo_sharpe = portafolios_especificos[\"sharpe\"][\"performance\"][1]\n",
    "    # Calcular sharpe de maximo sharpe portafolio\n",
    "    sharpe_sharpe = (rendimiento_sharpe - risk_free) / riesgo_sharpe\n",
    "\n",
    "    rendimiento_min_var = portafolios_especificos[\"min_vol\"][\"performance\"][0]\n",
    "    riesgo_min_var = portafolios_especificos[\"min_vol\"][\"performance\"][1]\n",
    "    \n",
    "    rendimiento_max_utility = portafolios_especificos[\"max_utility\"][\"performance\"][0]\n",
    "    riesgo_max_utility = portafolios_especificos[\"max_utility\"][\"performance\"][1]\n",
    "\n",
    "    rendimiento_igual = portafolios_especificos[\"equal\"][\"performance\"][0]\n",
    "    riesgo_igual = portafolios_especificos[\"equal\"][\"performance\"][1]\n",
    "\n",
    "    rendimiento_risk_limit = portafolios_especificos[\"risk_limit\"][\"performance\"][0]\n",
    "    riesgo_risk_limit = portafolios_especificos[\"risk_limit\"][\"performance\"][1]\n",
    "\n",
    "    # Calcular la frontera eficiente\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    frontier_returns = np.linspace(rendimiento_min_var, rendimiento_max_utility*(1-1e-6), 100)  # Adjusted line\n",
    "    frontier_volatility = []\n",
    "    for ret in frontier_returns:\n",
    "        ef.efficient_return(target_return=ret)\n",
    "        frontier_volatility.append(ef.portfolio_performance()[1])\n",
    "\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(portfolio_volatility, expected_returns_all*100, c=sharpe_ratios, cmap='viridis', alpha=0.5)\n",
    "    plt.colorbar(label='Ratio de Sharpe', pad=0.1) \n",
    "\n",
    "    # Mejorar el estilo de la gráfica\n",
    "    plt.xlabel('Volatilidad (Riesgo del Portafolio)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Rendimiento Esperado del Portafolio % (anual)', fontsize=12, fontweight='bold')\n",
    "    plt.suptitle(title, fontsize=18, fontweight='bold')\n",
    "    plt.title('Gráfica de Dispersión: Rendimiento vs. Volatilidad', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    # Añadir como linea la curva de frontera eficiente\n",
    "    plt.plot(frontier_volatility, frontier_returns*100, 'r--', linewidth=2, alpha = 0.7,label='Frontera Eficiente')\n",
    "\n",
    "    \n",
    "    # Añadir el punto del portafolio de mínima varianza en rojo\n",
    "    plt.scatter(riesgo_min_var, rendimiento_min_var*100, color='#FF3030', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Mínima Varianza')\n",
    "\n",
    "    # Añadir el punto del portafolio de pesos iguales en morado\n",
    "    plt.scatter(riesgo_igual, rendimiento_igual*100, color='#8B008B', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio Equal Weight')\n",
    "\n",
    "    # Añadir el punto del portafolio de máximo Sharpe en azul\n",
    "    plt.scatter(riesgo_sharpe, rendimiento_sharpe*100, color='#00FFFF', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Máximo Sharpe')\n",
    "    \n",
    "    # Añadir el punto del portafolio de máxima utilidad cuadrática en verde\n",
    "    plt.scatter(riesgo_max_utility, rendimiento_max_utility*100, color='#76EE00', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Máxima Utilidad Cuadrática')\n",
    "\n",
    "    # Añadir el punto del portafolio de riesgo fijo en naranja\n",
    "    plt.scatter(riesgo_risk_limit, rendimiento_risk_limit*100, color='#FFD700', s=150, marker='*', edgecolors='#1A1A1A', linewidth=0.8, label='Portafolio de Riesgo Fijo')\n",
    "\n",
    "    # Linea punteada horizontal que empiece en portafolio de minima varianza\n",
    "    plt.axhline(y=rendimiento_min_var*100, color='red', alpha= 0.7, linestyle='dotted', label='Frontera Minima Varianza')\n",
    "    \n",
    "    # Añadir los puntos de los activos individuales con etiquetas en la gráfica\n",
    "    for (asset, ret_asset, vol_asset, sharpe_asset) in portafolios_especificos[\"activos\"]:\n",
    "        plt.scatter(vol_asset, ret_asset*100, marker='o', s=35, edgecolors='black', facecolors='none')\n",
    "        #plt.text(vol_asset, (ret_asset*100), asset, fontsize=8, fontweight='bold', ha='center', color='#0A0A0A')\n",
    "\n",
    "    plt.legend(loc='upper left', fontsize=10, bbox_to_anchor=(0.01, 0.99)) \n",
    "    plt.text(0.5, 0.96, f'Tasa libre de riesgo: {risk_free*100:.2f}%', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "    # Añadir otro texto que muestre el ratio sharpe mas grande y el portafoio al que pertenece\n",
    "    plt.text(0.5, 0.93, f'Mejor Ratio de Sharpe: {sharpe_sharpe:.2f}', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "    # Añadir texto con minimo riesgo, y maximo rendimiento\n",
    "    #plt.text(0.5, 0.90, f'Riesgo Mínimo: {riesgo_min_var*100:.2f}%', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "    # Texto con pesos de portafolio maximo sharpe\n",
    "    #weights_sharpe = portafolios_especificos[\"sharpe\"][\"weights\"]\n",
    "    #texto_pesos_sharpe = f'Pesos del Portafolio de Máximo Sharpe:\\n{weights_sharpe}'\n",
    "    #plt.text(0.1, 0.05, texto_pesos_sharpe, transform=plt.gca().transAxes, fontsize=10, fontweight='bold', color='#363636')\n",
    "    \n",
    "    \n",
    "    #plt.text(0.5, 0.87, f'Rendimiento Máximo: {rendimiento_max_utility*100:.2f}%', transform=plt.gca().transAxes, fontsize=10,fontweight='bold', color='#363636')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Grafica pastel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_pies(data, risk_free=0.05, risk_limit=0.20, min_weight=0.0):\n",
    "    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit, min_weight=min_weight)\n",
    "    \n",
    "    portafolios = [\"sharpe\", \"min_vol\", \"equal\", \"max_utility\", \"risk_limit\"]\n",
    "    n_portfolios = len(portafolios)\n",
    "    \n",
    "    # Configurar el estilo de seaborn\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\", n_colors=len(data.columns))\n",
    "    \n",
    "    # Crear un mapa de colores consistente para los activos\n",
    "    color_map = dict(zip(data.columns, sns.color_palette(\"tab10\", n_colors=len(data.columns))))\n",
    "    \n",
    "    grafica= fig, axs = plt.subplots(1, n_portfolios, figsize=(20, 8))\n",
    "    fig.suptitle('Distribución de Activos en Diferentes Portafolios', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for i, portfolio in enumerate(portafolios):\n",
    "        weights = portafolios_especificos[portfolio]['weights']\n",
    "        \n",
    "        if isinstance(weights, dict):\n",
    "            assets = list(weights.keys())\n",
    "            values = list(weights.values())\n",
    "        else:\n",
    "            assets = data.columns\n",
    "            values = weights\n",
    "        \n",
    "        # Ordenar los valores y activos de mayor a menor\n",
    "        sorted_indices = np.argsort(values)[::-1]\n",
    "        sorted_values = np.array(values)[sorted_indices]\n",
    "        sorted_assets = np.array(assets)[sorted_indices]\n",
    "        \n",
    "        # Crear el gráfico de pastel\n",
    "        colors = [color_map[asset] for asset in sorted_assets]\n",
    "        wedges, _, autotexts = axs[i].pie(sorted_values, autopct='%1.1f%%', \n",
    "                                          startangle=90, colors=colors, \n",
    "                                          wedgeprops=dict(width=0.6, edgecolor='white'))\n",
    "        \n",
    "        # Ajustar el texto dentro de los wedges\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "\n",
    "        axs[i].set_title(f'Portafolio: {portfolio.capitalize()}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Añadir una única leyenda debajo del título principal\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color_map[asset], edgecolor='none') for asset in data.columns]\n",
    "    fig.legend(legend_elements, data.columns, loc='upper center', bbox_to_anchor=(0.5, 0.92),\n",
    "               ncol=len(data.columns), fontsize=10, title='Activos', title_fontsize=12)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.8, bottom=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Waffle chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_waffle(data, risk_free=0.05, risk_limit=0.20, min_weight=0.0):\n",
    "    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit, min_weight=min_weight)\n",
    "    \n",
    "    portafolios = [\"sharpe\", \"min_vol\", \"equal\", \"max_utility\", \"risk_limit\"]\n",
    "    n_portfolios = len(portafolios)\n",
    "    \n",
    "    # Configurar el estilo de seaborn\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\", n_colors=len(data.columns))\n",
    "    \n",
    "    # Crear un mapa de colores consistente para los activos\n",
    "    color_map = dict(zip(data.columns, sns.color_palette(\"tab10\", n_colors=len(data.columns))))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, n_portfolios, figsize=(25, 5))\n",
    "    fig.suptitle('Distribución de Activos en Diferentes Portafolios', fontsize=16, fontweight='bold')\n",
    "\n",
    "    def waffle_chart(weights, ax):\n",
    "        total = 100\n",
    "        values = [int(w * total) for w in weights.values()]\n",
    "        remainder = total - sum(values)\n",
    "        if remainder > 0:\n",
    "            values[-1] += remainder\n",
    "\n",
    "        colors = [color_map[asset] for asset in weights.keys()]\n",
    "        \n",
    "        data = []\n",
    "        for value, color in zip(values, colors):\n",
    "            data.extend([color] * value)\n",
    "\n",
    "        waffle = np.array(data).reshape((10, 10))\n",
    "        \n",
    "        ax.imshow(waffle, cmap=plt.cm.colors.ListedColormap(colors))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Añadir etiquetas\n",
    "        for asset, weight in weights.items():\n",
    "            if weight >= 0.03:  # Solo etiquetar si el peso es 3% o más\n",
    "                y, x = np.where(waffle == color_map[asset])\n",
    "                ax.text(x.mean(), y.mean(), f'{asset}\\n{weight:.1%}', \n",
    "                        ha='center', va='center', fontsize=8, fontweight='bold',\n",
    "                        bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "\n",
    "    for i, portfolio in enumerate(portafolios):\n",
    "        weights = portafolios_especificos[portfolio]['weights']\n",
    "        \n",
    "        if isinstance(weights, dict):\n",
    "            df = pd.DataFrame(list(weights.items()), columns=['Asset', 'Weight'])\n",
    "        else:\n",
    "            df = pd.DataFrame({'Asset': data.columns, 'Weight': weights})\n",
    "        \n",
    "        # Ordenar los valores de mayor a menor\n",
    "        df = df.sort_values('Weight', ascending=False)\n",
    "        \n",
    "        # Filtrar activos con peso mayor a 0\n",
    "        df = df[df['Weight'] > 0]\n",
    "        \n",
    "        weights_dict = dict(zip(df['Asset'], df['Weight']))\n",
    "        \n",
    "        waffle_chart(weights_dict, axs[i])\n",
    "        axs[i].set_title(f'Portafolio: {portfolio.capitalize()}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Añadir una única leyenda debajo del título principal\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color_map[asset], edgecolor='none') for asset in data.columns]\n",
    "    fig.legend(legend_elements, data.columns, loc='upper center', bbox_to_anchor=(0.5, 0.95),\n",
    "               ncol=len(data.columns), fontsize=10, title='Activos', title_fontsize=12)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.85, bottom=0.1)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Tree map chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squarify\n",
    "\n",
    "def plot_portfolio_treemap(data, risk_free=0.05, risk_limit=0.20, min_weight=0.0):\n",
    "    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit, min_weight=min_weight)\n",
    "    \n",
    "    portafolios = [\"sharpe\", \"min_vol\", \"equal\", \"max_utility\", \"risk_limit\"]\n",
    "    n_portfolios = len(portafolios)\n",
    "    \n",
    "    # Configurar el estilo de seaborn\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\", n_colors=len(data.columns))\n",
    "    \n",
    "    # Crear un mapa de colores consistente para los activos\n",
    "    color_map = dict(zip(data.columns, sns.color_palette(\"tab10\", n_colors=len(data.columns))))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, n_portfolios, figsize=(25, 5))\n",
    "    fig.suptitle('Distribución de Activos en Diferentes Portafolios', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for i, portfolio in enumerate(portafolios):\n",
    "        weights = portafolios_especificos[portfolio]['weights']\n",
    "        \n",
    "        if isinstance(weights, dict):\n",
    "            df = pd.DataFrame(list(weights.items()), columns=['Asset', 'Weight'])\n",
    "        else:\n",
    "            df = pd.DataFrame({'Asset': data.columns, 'Weight': weights})\n",
    "        \n",
    "        # Ordenar los valores de mayor a menor\n",
    "        df = df.sort_values('Weight', ascending=False)\n",
    "        \n",
    "        # Filtrar activos con peso mayor a 0\n",
    "        df = df[df['Weight'] > 0]\n",
    "        \n",
    "        # Crear el treemap\n",
    "        squarify.plot(sizes=df['Weight'], \n",
    "                      label=[f\"{asset}\\n{weight:.1%}\" if weight >= 0.03 else \"\" for asset, weight in zip(df['Asset'], df['Weight'])],\n",
    "                      color=[color_map[asset] for asset in df['Asset']],\n",
    "                      alpha=0.7,\n",
    "                      ax=axs[i])\n",
    "        \n",
    "        axs[i].set_title(f'Portafolio: {portfolio.capitalize()}', fontsize=12, fontweight='bold')\n",
    "        axs[i].axis('off')\n",
    "        \n",
    "        # Añadir etiquetas para activos con peso menor al 3%\n",
    "        for asset, weight, x, y in zip(df['Asset'], df['Weight'], \n",
    "                                       squarify.normalize_sizes(df['Weight'], 1, 1), \n",
    "                                       squarify.normalize_sizes(df['Weight'], 1, 1)):\n",
    "            if weight < 0.03:\n",
    "                axs[i].annotate(f\"{asset}: {weight:.1%}\", \n",
    "                                xy=(x, y), \n",
    "                                xytext=(3, 3), \n",
    "                                textcoords=\"offset points\",\n",
    "                                ha='left', \n",
    "                                va='bottom', \n",
    "                                fontsize=6,\n",
    "                                bbox=dict(boxstyle='round,pad=0.1', fc='white', alpha=0.7),\n",
    "                                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Añadir una única leyenda debajo del título principal\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color_map[asset], edgecolor='none') for asset in data.columns]\n",
    "    fig.legend(legend_elements, data.columns, loc='upper center', bbox_to_anchor=(0.5, 0.95),\n",
    "               ncol=len(data.columns), fontsize=10, title='Activos', title_fontsize=12)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.85, bottom=0.1)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### Columnas apiladass chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_stacked_bar(data, risk_free=0.05, risk_limit=0.20, min_weight=0.0):\n",
    "    portafolios_especificos = calcular_portafolios_especificos(data, risk_free, risk_limit, min_weight=min_weight)\n",
    "    \n",
    "    portafolios = [\"sharpe\", \"min_vol\", \"equal\", \"max_utility\", \"risk_limit\"]\n",
    "    \n",
    "    # Crear un DataFrame con todos los pesos\n",
    "    df = pd.DataFrame({p: portafolios_especificos[p]['weights'] for p in portafolios})\n",
    "    df = df.fillna(0)  # Rellenar NaN con 0 para activos que no están en algunos portafolios\n",
    "    \n",
    "    # Ordenar el DataFrame por la suma de los pesos en todos los portafolios\n",
    "    df = df.reindex(df.sum().sort_values(ascending=False).index, axis=1)\n",
    "    \n",
    "    # Configurar el estilo de seaborn\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Crear un mapa de colores consistente para los activos\n",
    "    color_map = dict(zip(df.columns, sns.color_palette(\"tab20\", n_colors=len(df.columns))))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    # Crear el gráfico de barras apiladas\n",
    "    bottom = np.zeros(len(portafolios))\n",
    "    for asset in df.columns:\n",
    "        ax.bar(portafolios, df.loc[asset], bottom=bottom, label=asset, color=color_map[asset])\n",
    "        bottom += df.loc[asset]\n",
    "    \n",
    "    # Personalizar el gráfico\n",
    "    ax.set_title('Composición de Diferentes Portafolios de Inversión', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Estrategias de Portafolio', fontsize=12)\n",
    "    ax.set_ylabel('Proporción de Activos', fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "    ax.set_yticklabels([f'{x:.0%}' for x in np.arange(0, 1.1, 0.1)])\n",
    "    \n",
    "    # Rotar las etiquetas del eje x para mejor legibilidad\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Añadir etiquetas de porcentaje en las barras\n",
    "    for i, portfolio in enumerate(portafolios):\n",
    "        cumsum = 0\n",
    "        for asset in df.columns:\n",
    "            weight = df.loc[asset, portfolio]\n",
    "            if weight > 0.03:  # Solo etiquetar si el peso es mayor al 3%\n",
    "                ax.text(i, cumsum + weight/2, f'{weight:.1%}', \n",
    "                        ha='center', va='center', fontweight='bold', fontsize=8,\n",
    "                        bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "            cumsum += weight\n",
    "    \n",
    "    # Añadir leyenda\n",
    "    ax.legend(title='Activos', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### _Drawdown y Rendimientos acumulados_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_and_drawdown(returns, benchmark='BTC'):\n",
    "    # Calcular rendimientos diarios y acumulados\n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "\n",
    "    # Calcular drawdowns\n",
    "    peak = cumulative_returns.cummax()\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "\n",
    "    # Configurar el estilo\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    colors = sns.color_palette(\"husl\", n_colors=len(returns.columns))\n",
    "    color_map = dict(zip(returns.columns, colors))\n",
    "\n",
    "    #csfont = {'fontname':'Times New Roman'}\n",
    "\n",
    "    # Crear la figura y los subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
    "    fig.suptitle('Rendimiento y Drawdown de Activos',fontsize=20, fontweight='bold')\n",
    "\n",
    "    # Subplot 1: Rendimiento acumulado (escala logarítmica)\n",
    "    for col in cumulative_returns.columns:\n",
    "        ax1.semilogy(cumulative_returns.index, 1 + cumulative_returns[col], label=col, color=color_map[col], linewidth=2)\n",
    "    \n",
    "    ax1.set_ylabel('Rendimiento Acumulado %', fontsize=12)\n",
    "    ax1.set_title('Rendimiento Acumulado (escala logarítmica)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Función para formatear el eje Y en porcentajes\n",
    "    def percent_formatter(y, pos):\n",
    "        return f'{(y-1)*100:.0f}%' #if y < 2 else f'{y-1:.0f}x'\n",
    "\n",
    "    ax1.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "    \n",
    "    # Crear escala personalizada para el eje Y\n",
    "    yticks = [1, 2, 3.5, 6, 11, 26, 51, 101, 151, 201, 251,301]\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_yticklabels([percent_formatter(y, 0) for y in yticks])\n",
    "\n",
    "    # Ajustar los límites del eje Y\n",
    "    ax1.set_ylim(bottom=max(0.1, 1 + cumulative_returns.min().min()), top=1 + cumulative_returns.max().max())\n",
    "\n",
    "    # Añadir líneas horizontales en el subplot de rendimiento\n",
    "    for y in yticks:\n",
    "        ax1.axhline(y=y, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Subplot 2: Drawdown\n",
    "    for col in drawdown.columns:\n",
    "        ax.fill_between(drawdown.index, drawdown[col], 0, label=col, color=color_map[col], alpha=0.7, linewidth=0.8, edgecolor='black')\n",
    "        # Hacerlo con lineas en vez de \n",
    "        #?ax2.plot(drawdown.index, drawdown[col], label=col, color=color_map[col], linewidth=2)    \n",
    "    ax2.set_ylabel('Drawdown %', fontsize=12)\n",
    "    ax2.set_title('Drawdown', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax2.set_ylim(-1, 0)\n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "    # Añadir línea de drawdown medio del benchmark\n",
    "    mean_drawdown = drawdown[benchmark].mean()\n",
    "    ax2.axhline(y=mean_drawdown, color='red', linestyle='--', linewidth=2)\n",
    "    ax2.text(drawdown.index[-1], mean_drawdown, f'Drawdown medio de {benchmark}: {mean_drawdown:.2%}', \n",
    "             verticalalignment='bottom', horizontalalignment='right', color='red', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def plot_cumulative_returns(data):\n",
    "    # Calcular rendimientos diarios y acumulados\n",
    "    returns = data.pct_change()\n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "\n",
    "    # Configurar el estilo\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    colors = sns.color_palette(\"tab10\", n_colors=len(data.columns))\n",
    "    color_map = dict(zip(data.columns, colors))\n",
    "\n",
    "    # Crear la figura\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    #fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Rendimiento acumulado (escala logarítmica)\n",
    "    for col in cumulative_returns.columns:\n",
    "        ax.semilogy(cumulative_returns.index, 1 + cumulative_returns[col], label=col, color=color_map[col], linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel('Rendimiento Acumulado %', fontsize=12)\n",
    "    ax.set_title('Rendimiento Acumulado (escala logarítmica)', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "   # Función para formatear el eje Y en porcentajes\n",
    "    def percent_formatter(y, pos):\n",
    "        return f'{(y-1)*100:.0f}%'\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(percent_formatter))  \n",
    "    # Crear escala personalizada para el eje Y\n",
    "    #[1, 2, 3.5, 6, 11, 26, 51, 101, 151, 201, 251, 301]\n",
    "    yticks = [1,1.5,2,3,4,5]\n",
    "\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([percent_formatter(y, 0) for y in yticks])\n",
    "    # Ajustar los límites del eje Y\n",
    "    ax.set_ylim(bottom=1 + cumulative_returns.min().min(), top=1 + cumulative_returns.max().max())\n",
    "\n",
    "    # Añadir líneas horizontales\n",
    "    for y in yticks:\n",
    "        ax.axhline(y=y, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "def plot_drawdown(returns, benchmark='BTC'):\n",
    "    # Calcular rendimientos diarios y acumulados\n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "\n",
    "    # Calcular drawdowns\n",
    "    peak = cumulative_returns.cummax()\n",
    "    drawdown = (cumulative_returns - peak) / peak\n",
    "\n",
    "    # Configurar el estilo\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    colors = sns.color_palette(\"husl\", n_colors=len(returns.columns))\n",
    "    color_map = dict(zip(returns.columns, colors))\n",
    "\n",
    "    # Crear la figura\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    fig.suptitle('Drawdown de Activos (Underwater)', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Drawdown\n",
    "    for col in drawdown.columns:\n",
    "        ax.fill_between(drawdown.index, drawdown[col], 0, label=col, color=color_map[col], alpha=0.7, linewidth=0.8, edgecolor='black')\n",
    "    \n",
    "    ax.set_ylabel('Drawdown %', fontsize=12)\n",
    "    ax.set_title('Drawdown', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_ylim(-1, 0)\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "    # Añadir línea de drawdown medio del benchmark\n",
    "    mean_drawdown = drawdown[benchmark].mean()\n",
    "    ax.axhline(y=mean_drawdown, color='red', linestyle='--', linewidth=2)\n",
    "    ax.text(drawdown.index[-1], mean_drawdown, f'Drawdown medio de {benchmark}: {mean_drawdown:.2%}', \n",
    "            verticalalignment='bottom', horizontalalignment='right', color='red', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(returns, yticks=[1, 2, 3, 4, 5, 6], num_minor_ticks=4):\n",
    "    # Calcular rendimientos diarios y acumulados\n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "\n",
    "    # Configurar el estilo\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    colors = sns.color_palette(\"tab10\", n_colors=len(returns.columns))\n",
    "    color_map = dict(zip(returns.columns, colors))\n",
    "\n",
    "    # Crear la figura\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    # Graficar el rendimiento acumulado (escala logarítmica)\n",
    "    for col in cumulative_returns.columns:\n",
    "        ax.semilogy(cumulative_returns.index, 1 + cumulative_returns[col], label=col, color=color_map[col], linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel('Rendimiento Acumulado %', fontsize=12)\n",
    "    ax.set_title('Rendimiento Acumulado (escala logarítmica)', fontsize=16, fontweight='bold')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Función para formatear el eje Y en porcentajes\n",
    "    def percent_formatter(y, pos):\n",
    "        return f'{(y-1)/10:.0f}k%' if y > 10 else f'{(y-1)*100:.0f}%'\n",
    "    #f'{(y-1)*100:.0f}%'\n",
    "# para hacer que las centenas se vean como 100x se usa el siguiente codigo\n",
    "#     def percent_formatter(y, pos): \n",
    "#         return f'{y-1:.0f}x' if y > 1 else f'{(y-1)*100:.0f}%'\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "\n",
    "    # Crear escala personalizada para el eje Y\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([percent_formatter(y, 0) for y in yticks], fontsize=8.5)\n",
    "\n",
    "    # Añadir líneas horizontales principales\n",
    "    for y in yticks:\n",
    "        ax.axhline(y=y, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Añadir líneas horizontales secundarias entre los ticks principales sin etiquetas\n",
    "    minor_ticks = []\n",
    "    for i in range(len(yticks) - 1):\n",
    "        start, end = yticks[i], yticks[i + 1]\n",
    "        minor_ticks.extend(np.linspace(start, end, num_minor_ticks + 2)[1:-1])  # Dividir en partes iguales y excluir start y end\n",
    "\n",
    "    ax.yaxis.set_minor_locator(plt.FixedLocator(minor_ticks))\n",
    "    ax.grid(True, which='minor', axis='y', linestyle='--', linewidth=0.4, alpha=0.45)\n",
    "    \n",
    "    # Asegurarse de que las etiquetas menores no se muestren\n",
    "    ax.yaxis.set_minor_formatter(plt.NullFormatter())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns2(returns, num_parts=10, num_minor_ticks=4):\n",
    "    # Calcular rendimientos diarios y acumulados\n",
    "    cumulative_returns = (1 + returns).cumprod() - 1\n",
    "\n",
    "    # Configurar el estilo\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    colors = sns.color_palette(\"tab10\", n_colors=len(returns.columns))\n",
    "    color_map = dict(zip(returns.columns, colors))\n",
    "\n",
    "    # Crear la figura\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "    # Graficar el rendimiento acumulado (escala logarítmica)\n",
    "    for col in cumulative_returns.columns:\n",
    "        ax.semilogy(cumulative_returns.index, 1 + cumulative_returns[col], label=col, color=color_map[col], linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel('Rendimiento Acumulado %', fontsize=12)\n",
    "    ax.set_title('Rendimiento Acumulado (escala logarítmica)', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Función para formatear el eje Y en porcentajes\n",
    "    def percent_formatter(y, pos):\n",
    "        return f'{(y-1)/10:.0f}k%' if y > 10 else f'{(y-1)*100:.0f}%'\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "\n",
    "    # Obtener el mínimo y máximo de los valores acumulados\n",
    "    min_val = 1 + cumulative_returns.min().min()\n",
    "    max_val = 1 + cumulative_returns.max().max()\n",
    "\n",
    "    # Crear escala personalizada para el eje Y dividiendo el rango en `num_parts` partes\n",
    "    yticks = np.linspace(min_val, max_val, num_parts)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([percent_formatter(y, 0) for y in yticks])\n",
    "\n",
    "    # Añadir líneas horizontales principales\n",
    "    for y in yticks:\n",
    "        ax.axhline(y=y, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Añadir líneas horizontales secundarias entre los ticks principales sin etiquetas\n",
    "    minor_ticks = []\n",
    "    for i in range(len(yticks) - 1):\n",
    "        start, end = yticks[i], yticks[i + 1]\n",
    "        minor_ticks.extend(np.linspace(start, end, num_minor_ticks + 2)[1:-1])  # Dividir en partes iguales y excluir start y end\n",
    "\n",
    "    ax.yaxis.set_minor_locator(plt.FixedLocator(minor_ticks))\n",
    "    ax.grid(True, which='minor', axis='y', linestyle='--', linewidth=0.4, alpha=0.45)\n",
    "    \n",
    "    # Asegurarse de que las etiquetas menores no se muestren\n",
    "    ax.yaxis.set_minor_formatter(plt.NullFormatter())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matriz de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para graficar matriz de correlacion de activos\n",
    "def graficar_matriz_correlacion(data):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    data = data.pct_change().corr()\n",
    "    sns.heatmap(data, annot=True, cmap='coolwarm', fmt=\".4f\", vmin=data.min(), vmax=1)\n",
    "    plt.title('Matriz de Correlación de Activos', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### _Meticas clave_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener key metrics de los portafolios con quantstats\n",
    "def key_metrics_html(rendimientos, risk_free=0.05, mode='full'):\n",
    "    return qs.reports.html(rendimientos, output='report.html', rf=risk_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_metrics(rendimientos, risk_free=0.05, mode='full'):\n",
    "    return qs.reports.metrics(rendimientos, mode=mode, rf=risk_free)\n",
    "\n",
    "def key_plots(rendimientos, risk_free=0.05, mode='full'):\n",
    "    return qs.reports.plots(rendimientos, mode=mode, rf=risk_free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cadenas de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_regresion(prices,column='SP500', order=1, trend='n', results=False, data=False):\n",
    "    returns = prices.pct_change().dropna()\n",
    "    model = sm.tsa.MarkovRegression(returns[column], k_regimes=2, order=order, trend=trend, switching_variance=True)\n",
    "    results = model.fit()\n",
    "    \n",
    "    if results == True:\n",
    "        return results.summary()\n",
    "    \n",
    "    elif data == True:\n",
    "        return results.smoothed_marginal_probabilities\n",
    "        \n",
    "    else: \n",
    "        low_var = results.smoothed_marginal_probabilities[0]\n",
    "        high_var = results.smoothed_marginal_probabilities[1]\n",
    "        data_low_var = data1[low_var>high_var] \n",
    "        data_high_var = data1[high_var>low_var]\n",
    "        return {\n",
    "            'l_var': data_low_var,\n",
    "            'h_var': data_high_var\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_cumrends_plot_line(prices, column='SP500', order=1, trend='n'):\n",
    "    # Calcular rendimientos y rendimientos acumulados\n",
    "    rends = prices[column].pct_change().dropna()\n",
    "    cum_rends = (1 + rends).cumprod() - 1\n",
    "    \n",
    "    # Obtener los datos de baja y alta volatilidad\n",
    "    data = markov_regresion(prices, column=column, order=order, trend=trend)\n",
    "    low_var = data['l_var']\n",
    "    high_var = data['h_var']\n",
    "    \n",
    "    # Crear un DataFrame base con los rendimientos acumulados\n",
    "    df = pd.DataFrame({\n",
    "        'cum_rends': cum_rends\n",
    "    })\n",
    "    \n",
    "    # Inicializar columnas para las secciones de baja y alta volatilidad\n",
    "    df['Rend_Acum_Low'] = np.where(df.index.isin(low_var.index), df['cum_rends'], np.nan)\n",
    "    df['Rend_Acum_High'] = np.where(df.index.isin(high_var.index), df['cum_rends'], np.nan)\n",
    "\n",
    "    # Crear una figura y un eje\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    # Graficar las secciones de baja volatilidad como líneas verdes\n",
    "    plt.plot(df.index, df['Rend_Acum_Low'], color='green', label='Baja Volatilidad')\n",
    "\n",
    "    # Graficar las secciones de alta volatilidad como líneas rojas\n",
    "    plt.plot(df.index, df['Rend_Acum_High'], color='red', label='Alta Volatilidad')\n",
    "\n",
    "    # Añadir título y leyenda\n",
    "    plt.title('Rendimientos Acumulados con Zonas de Volatilidad')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.show()\n",
    "    \n",
    "    #! Grafica scatter\n",
    "def markov_cumrends_scatter_plot(prices, column='SP500', order=1, trend='n'):\n",
    "    # Calcular rendimientos y rendimientos acumulados\n",
    "    rends = prices[column].pct_change().dropna()\n",
    "    cum_rends = (1 + rends).cumprod() - 1\n",
    "    \n",
    "    # Obtener los datos de baja y alta volatilidad\n",
    "    data = markov_regresion(prices, column=column, order=order, trend=trend)\n",
    "    low_var = data['l_var']\n",
    "    high_var = data['h_var']\n",
    "    \n",
    "    # Crear un DataFrame base con los rendimientos acumulados\n",
    "    df = pd.DataFrame({\n",
    "        'cum_rends': cum_rends\n",
    "    })\n",
    "    \n",
    "    # Crear una figura y un eje\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    # Graficar los puntos de baja volatilidad como scatter en verde\n",
    "    plt.scatter(low_var.index, cum_rends[low_var.index], color='green', label='Baja Volatilidad', s=10)\n",
    "\n",
    "    # Graficar los puntos de alta volatilidad como scatter en rojo\n",
    "    plt.scatter(high_var.index, cum_rends[high_var.index], color='red', label='Alta Volatilidad', s=10)\n",
    "\n",
    "    # Graficar la línea continua de rendimientos acumulados\n",
    "    #plt.plot(df.index, df['cum_rends'], color='black', alpha=0.1, label='Rendimientos Acumulados')\n",
    "\n",
    "    # Añadir título y leyenda\n",
    "    plt.title('Rendimientos Acumulados con Zonas de Volatilidad (Scatter)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar el gráfico\n",
    "    plt.show()\n",
    "    \n",
    "def markov_prob_plot(prices,column='SP500', order=1, trend='n'):\n",
    "    data=markov_regresion(prices,column=column, order=order, trend=trend,data=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, figsize=(10,7))\n",
    "    ax = axes[0]\n",
    "    ax.plot(data[0])\n",
    "    ax.grid(True, alpha=0.7, color='#F0FFFF')\n",
    "    ax.set(title='Smoothed probability of a low-variance regime returns')\n",
    "    ax = axes[1]\n",
    "    ax.plot(data[1])\n",
    "    ax.set(title='Smoothed probability of a high-variance regime returns')\n",
    "    fig.tight_layout()\n",
    "    ax.grid(True, alpha=0.7, color='#F0FFFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha de inicio\n",
    "start = '2017-01-01'\n",
    "#start = '2020-04-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BNB</th>\n",
       "      <th>BTC</th>\n",
       "      <th>ETH</th>\n",
       "      <th>TRX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09 00:00:00+00:00</th>\n",
       "      <td>1.99077</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10 00:00:00+00:00</th>\n",
       "      <td>1.79684</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>0.002013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11 00:00:00+00:00</th>\n",
       "      <td>1.67047</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>0.002003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12 00:00:00+00:00</th>\n",
       "      <td>1.51969</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13 00:00:00+00:00</th>\n",
       "      <td>1.68662</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>0.002112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               BNB          BTC         ETH       TRX\n",
       "Date                                                                 \n",
       "2017-11-09 00:00:00+00:00  1.99077  7143.580078  320.884003  0.002344\n",
       "2017-11-10 00:00:00+00:00  1.79684  6618.140137  299.252991  0.002013\n",
       "2017-11-11 00:00:00+00:00  1.67047  6357.600098  314.681000  0.002003\n",
       "2017-11-12 00:00:00+00:00  1.51969  5950.069824  307.907990  0.001783\n",
       "2017-11-13 00:00:00+00:00  1.68662  6559.490234  316.716003  0.002112"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener datos de criptomonedas con Yahoo Finance\n",
    "tk_cry = ['BTC-USD', 'ETH-USD', 'TRX-USD', 'BNB-USD']\n",
    "tk_cry.sort() #? Se deben ordenar alfabeticamente para que coincidan con los nombres de las columnas\n",
    "cripto = yf.download(tk_cry, start=start)['Adj Close']\n",
    "cripto.columns = [tk.split('-')[0] for tk in tk_cry]\n",
    "cripto.dropna(inplace=True)\n",
    "cripto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEM</th>\n",
       "      <th>VWO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03 00:00:00+00:00</th>\n",
       "      <td>30.130545</td>\n",
       "      <td>29.234997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04 00:00:00+00:00</th>\n",
       "      <td>30.360161</td>\n",
       "      <td>29.501722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>30.691826</td>\n",
       "      <td>29.808861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>30.564255</td>\n",
       "      <td>29.687626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09 00:00:00+00:00</th>\n",
       "      <td>30.538748</td>\n",
       "      <td>29.639128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 EEM        VWO\n",
       "Date                                           \n",
       "2017-01-03 00:00:00+00:00  30.130545  29.234997\n",
       "2017-01-04 00:00:00+00:00  30.360161  29.501722\n",
       "2017-01-05 00:00:00+00:00  30.691826  29.808861\n",
       "2017-01-06 00:00:00+00:00  30.564255  29.687626\n",
       "2017-01-09 00:00:00+00:00  30.538748  29.639128"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener datos de ETF mercados emergentes\n",
    "tk_emerg_etf = ['EEM', 'VWO']\n",
    "tk_emerg_etf.sort()\n",
    "emerg_etf = yf.download(tk_emerg_etf, start=start)['Adj Close']\n",
    "emerg_etf.columns = ['EEM', 'VWO']\n",
    "emerg_etf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE</th>\n",
       "      <th>NIKKEI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-02 00:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11598.330078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03 00:00:00+00:00</th>\n",
       "      <td>7177.899902</td>\n",
       "      <td>11584.240234</td>\n",
       "      <td>2257.830078</td>\n",
       "      <td>5429.080078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04 00:00:00+00:00</th>\n",
       "      <td>7189.700195</td>\n",
       "      <td>11584.309570</td>\n",
       "      <td>2270.750000</td>\n",
       "      <td>5477.000000</td>\n",
       "      <td>19594.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>7195.299805</td>\n",
       "      <td>11584.940430</td>\n",
       "      <td>2269.000000</td>\n",
       "      <td>5487.939941</td>\n",
       "      <td>19520.689453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>7210.100098</td>\n",
       "      <td>11599.009766</td>\n",
       "      <td>2276.979980</td>\n",
       "      <td>5521.060059</td>\n",
       "      <td>19454.330078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 SP500        NASDAQ          DAX  \\\n",
       "Date                                                                \n",
       "2017-01-02 00:00:00+00:00          NaN  11598.330078          NaN   \n",
       "2017-01-03 00:00:00+00:00  7177.899902  11584.240234  2257.830078   \n",
       "2017-01-04 00:00:00+00:00  7189.700195  11584.309570  2270.750000   \n",
       "2017-01-05 00:00:00+00:00  7195.299805  11584.940430  2269.000000   \n",
       "2017-01-06 00:00:00+00:00  7210.100098  11599.009766  2276.979980   \n",
       "\n",
       "                                  FTSE        NIKKEI  \n",
       "Date                                                  \n",
       "2017-01-02 00:00:00+00:00          NaN           NaN  \n",
       "2017-01-03 00:00:00+00:00  5429.080078           NaN  \n",
       "2017-01-04 00:00:00+00:00  5477.000000  19594.160156  \n",
       "2017-01-05 00:00:00+00:00  5487.939941  19520.689453  \n",
       "2017-01-06 00:00:00+00:00  5521.060059  19454.330078  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener datos de principales indices del mundo\n",
    "tk_major_ind = ['^GSPC', '^IXIC', '^GDAXI', '^FTSE', '^N225']\n",
    "major_ind = yf.download(tk_major_ind, start=start,threads=True )['Adj Close']\n",
    "# Crear un diccionario para mapear tickers a nombres\n",
    "tk_major_ind_ordered = {\n",
    "    '^GSPC': 'SP500',\n",
    "    '^IXIC': 'NASDAQ',\n",
    "    '^GDAXI': 'DAX',\n",
    "    '^FTSE': 'FTSE',\n",
    "    '^N225': 'NIKKEI'\n",
    "}\n",
    "# Renombrar las columnas utilizando el diccionario\n",
    "major_ind.columns = tk_major_ind_ordered.values()\n",
    "major_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  20 of 20 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "['^PSEI', '^FTSEJSE', '^EGX30', '^JN0U.FGI']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>CHN</th>\n",
       "      <th>TUR</th>\n",
       "      <th>IND</th>\n",
       "      <th>HUN</th>\n",
       "      <th>BRA</th>\n",
       "      <th>EGY</th>\n",
       "      <th>ZAF</th>\n",
       "      <th>CHL</th>\n",
       "      <th>IDN</th>\n",
       "      <th>KOR</th>\n",
       "      <th>MYS</th>\n",
       "      <th>TWN</th>\n",
       "      <th>COL</th>\n",
       "      <th>MEX</th>\n",
       "      <th>RUS</th>\n",
       "      <th>PHL</th>\n",
       "      <th>THA</th>\n",
       "      <th>PER</th>\n",
       "      <th>ARG</th>\n",
       "      <th>POL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-02 00:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26595.449219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026.160034</td>\n",
       "      <td>17505.0</td>\n",
       "      <td>45695.101562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03 00:00:00+00:00</th>\n",
       "      <td>3135.920898</td>\n",
       "      <td>656.609985</td>\n",
       "      <td>26643.240234</td>\n",
       "      <td>32169.130859</td>\n",
       "      <td>61814.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4148.859863</td>\n",
       "      <td>5275.971191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1635.530029</td>\n",
       "      <td>2043.969971</td>\n",
       "      <td>17911.0</td>\n",
       "      <td>46123.359375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15827.549805</td>\n",
       "      <td>9272.873047</td>\n",
       "      <td>52532.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04 00:00:00+00:00</th>\n",
       "      <td>3158.793945</td>\n",
       "      <td>657.539978</td>\n",
       "      <td>26633.130859</td>\n",
       "      <td>32649.039062</td>\n",
       "      <td>61589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4168.339844</td>\n",
       "      <td>5301.183105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1647.469971</td>\n",
       "      <td>2045.640015</td>\n",
       "      <td>18143.0</td>\n",
       "      <td>46587.738281</td>\n",
       "      <td>19594.160156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1563.579956</td>\n",
       "      <td>15970.519531</td>\n",
       "      <td>9286.953125</td>\n",
       "      <td>52753.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>3165.410889</td>\n",
       "      <td>660.299988</td>\n",
       "      <td>26878.240234</td>\n",
       "      <td>32750.000000</td>\n",
       "      <td>62071.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4163.649902</td>\n",
       "      <td>5325.503906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1659.819946</td>\n",
       "      <td>2041.949951</td>\n",
       "      <td>18223.0</td>\n",
       "      <td>46719.988281</td>\n",
       "      <td>19520.689453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1571.050049</td>\n",
       "      <td>16036.089844</td>\n",
       "      <td>9358.132812</td>\n",
       "      <td>52721.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>3154.321045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26759.230469</td>\n",
       "      <td>32855.871094</td>\n",
       "      <td>61665.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4171.140137</td>\n",
       "      <td>5347.021973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675.489990</td>\n",
       "      <td>2049.120117</td>\n",
       "      <td>18284.0</td>\n",
       "      <td>46071.570312</td>\n",
       "      <td>19454.330078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1571.479980</td>\n",
       "      <td>15984.809570</td>\n",
       "      <td>9372.212891</td>\n",
       "      <td>52721.671875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker                             CHN         TUR           IND  \\\n",
       "Date                                                               \n",
       "2017-01-02 00:00:00+00:00          NaN         NaN  26595.449219   \n",
       "2017-01-03 00:00:00+00:00  3135.920898  656.609985  26643.240234   \n",
       "2017-01-04 00:00:00+00:00  3158.793945  657.539978  26633.130859   \n",
       "2017-01-05 00:00:00+00:00  3165.410889  660.299988  26878.240234   \n",
       "2017-01-06 00:00:00+00:00  3154.321045         NaN  26759.230469   \n",
       "\n",
       "Ticker                              HUN      BRA  EGY  ZAF          CHL  \\\n",
       "Date                                                                      \n",
       "2017-01-02 00:00:00+00:00           NaN  59589.0  NaN  NaN          NaN   \n",
       "2017-01-03 00:00:00+00:00  32169.130859  61814.0  NaN  NaN  4148.859863   \n",
       "2017-01-04 00:00:00+00:00  32649.039062  61589.0  NaN  NaN  4168.339844   \n",
       "2017-01-05 00:00:00+00:00  32750.000000  62071.0  NaN  NaN  4163.649902   \n",
       "2017-01-06 00:00:00+00:00  32855.871094  61665.0  NaN  NaN  4171.140137   \n",
       "\n",
       "Ticker                             IDN  KOR          MYS          TWN  \\\n",
       "Date                                                                    \n",
       "2017-01-02 00:00:00+00:00          NaN  NaN          NaN  2026.160034   \n",
       "2017-01-03 00:00:00+00:00  5275.971191  NaN  1635.530029  2043.969971   \n",
       "2017-01-04 00:00:00+00:00  5301.183105  NaN  1647.469971  2045.640015   \n",
       "2017-01-05 00:00:00+00:00  5325.503906  NaN  1659.819946  2041.949951   \n",
       "2017-01-06 00:00:00+00:00  5347.021973  NaN  1675.489990  2049.120117   \n",
       "\n",
       "Ticker                         COL           MEX           RUS  PHL  \\\n",
       "Date                                                                  \n",
       "2017-01-02 00:00:00+00:00  17505.0  45695.101562           NaN  NaN   \n",
       "2017-01-03 00:00:00+00:00  17911.0  46123.359375           NaN  NaN   \n",
       "2017-01-04 00:00:00+00:00  18143.0  46587.738281  19594.160156  NaN   \n",
       "2017-01-05 00:00:00+00:00  18223.0  46719.988281  19520.689453  NaN   \n",
       "2017-01-06 00:00:00+00:00  18284.0  46071.570312  19454.330078  NaN   \n",
       "\n",
       "Ticker                             THA           PER          ARG  \\\n",
       "Date                                                                \n",
       "2017-01-02 00:00:00+00:00          NaN           NaN          NaN   \n",
       "2017-01-03 00:00:00+00:00          NaN  15827.549805  9272.873047   \n",
       "2017-01-04 00:00:00+00:00  1563.579956  15970.519531  9286.953125   \n",
       "2017-01-05 00:00:00+00:00  1571.050049  16036.089844  9358.132812   \n",
       "2017-01-06 00:00:00+00:00  1571.479980  15984.809570  9372.212891   \n",
       "\n",
       "Ticker                              POL  \n",
       "Date                                     \n",
       "2017-01-02 00:00:00+00:00           NaN  \n",
       "2017-01-03 00:00:00+00:00  52532.351562  \n",
       "2017-01-04 00:00:00+00:00  52753.839844  \n",
       "2017-01-05 00:00:00+00:00  52721.671875  \n",
       "2017-01-06 00:00:00+00:00  52721.671875  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de indices principales de Mexico, brasil, china, india, rusia, turquia, colombia, argentina, taiwan, corea del sur, sudafrica, indonesia, tailandia, malasia, filipinas, polonia, hungria, chile, peru, egipto\n",
    "tk_emerging_markets = ['^MXX', '^BVSP', '000001.SS', '^BSESN', '^N225', '^ATG', '^MERV', '^TWII', '^KS11', '^JN0U.FGI', '^FTSEJSE', '^JKSE', '^SET.BK', '^KLSE', '^PSEI', '^WIG', '^BUX', '^IPSA', '^SPBLPGPT', '^EGX30']\n",
    "emerging_markets = yf.download(tk_emerging_markets, start=start)['Adj Close']\n",
    "# Crear un diccionario para mapear tickers a nombres\n",
    "tk_emerging_markets_ordered = {\n",
    "    '^MXX': 'MEX',\n",
    "    '^BVSP': 'BRA',\n",
    "    '000001.SS': 'CHN',\n",
    "    '^BSESN': 'IND',\n",
    "    '^N225': 'RUS',\n",
    "    '^ATG': 'TUR',\n",
    "    '^MERV': 'COL',\n",
    "    '^TWII': 'ARG',\n",
    "    '^KS11': 'TWN',\n",
    "    '^JN0U.FGI': 'KOR',\n",
    "    '^FTSEJSE': 'ZAF',\n",
    "    '^JKSE': 'IDN',\n",
    "    '^SET.BK': 'THA',\n",
    "    '^KLSE': 'MYS',\n",
    "    '^PSEI': 'PHL',\n",
    "    '^WIG': 'POL',\n",
    "    '^BUX': 'HUN',\n",
    "    '^IPSA': 'CHL',\n",
    "    '^SPBLPGPT': 'PER',\n",
    "    '^EGX30': 'EGY'\n",
    "}\n",
    "emerging_markets.rename(columns=tk_emerging_markets_ordered, inplace=True)\n",
    "emerging_markets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>Oil</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03 00:00:00+00:00</th>\n",
       "      <td>52.330002</td>\n",
       "      <td>1160.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04 00:00:00+00:00</th>\n",
       "      <td>53.259998</td>\n",
       "      <td>1163.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>53.759998</td>\n",
       "      <td>1179.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>53.990002</td>\n",
       "      <td>1171.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09 00:00:00+00:00</th>\n",
       "      <td>51.959999</td>\n",
       "      <td>1183.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker                           Oil         Gold\n",
       "Date                                             \n",
       "2017-01-03 00:00:00+00:00  52.330002  1160.400024\n",
       "2017-01-04 00:00:00+00:00  53.259998  1163.800049\n",
       "2017-01-05 00:00:00+00:00  53.759998  1179.699951\n",
       "2017-01-06 00:00:00+00:00  53.990002  1171.900024\n",
       "2017-01-09 00:00:00+00:00  51.959999  1183.500000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de materias, oro, petroleo\n",
    "tk_commodities = ['GC=F', 'CL=F']\n",
    "commodities = yf.download(tk_commodities, start=start)['Adj Close']\n",
    "# Crear un diccionario para mapear tickers a nombres\n",
    "tk_commodities_ordered = {\n",
    "    'GC=F': 'Gold',\n",
    "    'CL=F': 'Oil'\n",
    "}\n",
    "commodities.rename(columns=tk_commodities_ordered, inplace=True)\n",
    "commodities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>EURUSD</th>\n",
       "      <th>GBPUSD</th>\n",
       "      <th>JPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-02 00:00:00+00:00</th>\n",
       "      <td>1.052698</td>\n",
       "      <td>1.234903</td>\n",
       "      <td>116.794998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03 00:00:00+00:00</th>\n",
       "      <td>1.046003</td>\n",
       "      <td>1.228199</td>\n",
       "      <td>117.495003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04 00:00:00+00:00</th>\n",
       "      <td>1.041992</td>\n",
       "      <td>1.224560</td>\n",
       "      <td>117.658997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>1.050089</td>\n",
       "      <td>1.232681</td>\n",
       "      <td>117.112999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>1.060592</td>\n",
       "      <td>1.242545</td>\n",
       "      <td>115.264999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker                       EURUSD    GBPUSD         JPY\n",
       "Date                                                     \n",
       "2017-01-02 00:00:00+00:00  1.052698  1.234903  116.794998\n",
       "2017-01-03 00:00:00+00:00  1.046003  1.228199  117.495003\n",
       "2017-01-04 00:00:00+00:00  1.041992  1.224560  117.658997\n",
       "2017-01-05 00:00:00+00:00  1.050089  1.232681  117.112999\n",
       "2017-01-06 00:00:00+00:00  1.060592  1.242545  115.264999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de divisas\n",
    "tk_fx = ['EURUSD=X', 'JPY=X', 'GBPUSD=X']\n",
    "fx = yf.download(tk_fx, start=start)['Adj Close']\n",
    "# Crear un diccionario para mapear tickers a nombres\n",
    "tk_fx_ordered = {\n",
    "    'EURUSD=X': 'EURUSD',\n",
    "    'JPY=X': 'JPY',\n",
    "    'GBPUSD=X': 'GBPUSD'\n",
    "}\n",
    "fx.rename(columns=tk_fx_ordered, inplace=True)\n",
    "fx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Crear portafolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = major_ind\n",
    "risk_free=0.05\n",
    "risk_limit=0.20\n",
    "min_weight=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_cripto = add_cripto(data, cripto, ['BTC', 'ETH', 'BNB'])\n",
    "\n",
    "data_w_cripto_port = generate_portfolio_df(data_w_cripto, \n",
    "                      use_returns=False,\n",
    "                      include_sharpe=True, \n",
    "                      include_min_vol=True, \n",
    "                      include_max_return=True,\n",
    "                      include_equal_weight=True, \n",
    "                      include_risk_limit=True, \n",
    "                      risk_free=risk_free, \n",
    "                      risk_limit=risk_limit,\n",
    "                      min_weight=min_weight,\n",
    "                      include_assets=False,\n",
    "                      save_weights=False)\n",
    "data_port = generate_portfolio_df(data,\n",
    "                      use_returns=False,\n",
    "                      include_sharpe=True, \n",
    "                      include_min_vol=True, \n",
    "                      include_max_return=True,\n",
    "                      include_equal_weight=True, \n",
    "                      include_risk_limit=True, \n",
    "                      risk_free=risk_free, \n",
    "                      risk_limit=risk_limit,\n",
    "                      min_weight=min_weight,\n",
    "                      include_assets=False,\n",
    "                      save_weights=False)\n",
    "data_port.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_Sharpe</th>\n",
       "      <th>Min_Volatility</th>\n",
       "      <th>Max_Return</th>\n",
       "      <th>Equal_Weight</th>\n",
       "      <th>Risk_Limit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.004244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10 00:00:00+00:00</th>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-11 00:00:00+00:00</th>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.002348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12 00:00:00+00:00</th>\n",
       "      <td>-0.004498</td>\n",
       "      <td>-0.003958</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>-0.004607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Max_Sharpe  Min_Volatility  Max_Return  \\\n",
       "Date                                                                \n",
       "2017-01-05 00:00:00+00:00    0.000977       -0.000944    0.001997   \n",
       "2017-01-06 00:00:00+00:00    0.004360        0.000743    0.006035   \n",
       "2017-01-10 00:00:00+00:00    0.003187        0.001064    0.005571   \n",
       "2017-01-11 00:00:00+00:00    0.002334        0.002605    0.002131   \n",
       "2017-01-12 00:00:00+00:00   -0.004498       -0.003958   -0.002905   \n",
       "\n",
       "                           Equal_Weight  Risk_Limit  \n",
       "Date                                                 \n",
       "2017-01-05 00:00:00+00:00     -0.000338    0.000907  \n",
       "2017-01-06 00:00:00+00:00      0.001885    0.004244  \n",
       "2017-01-10 00:00:00+00:00      0.000376    0.003022  \n",
       "2017-01-11 00:00:00+00:00      0.003145    0.002348  \n",
       "2017-01-12 00:00:00+00:00     -0.005482   -0.004607  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_port.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500</th>\n",
       "      <th>NASDAQ</th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE</th>\n",
       "      <th>NIKKEI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00+00:00</th>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>-0.003750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00+00:00</th>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>-0.003399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09 00:00:00+00:00</th>\n",
       "      <td>0.003842</td>\n",
       "      <td>-0.003019</td>\n",
       "      <td>-0.003549</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10 00:00:00+00:00</th>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>-0.007859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-11 00:00:00+00:00</th>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.003276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              SP500    NASDAQ       DAX      FTSE    NIKKEI\n",
       "Date                                                                       \n",
       "2017-01-05 00:00:00+00:00  0.000779  0.000054 -0.000771  0.001997 -0.003750\n",
       "2017-01-06 00:00:00+00:00  0.002057  0.001214  0.003517  0.006035 -0.003399\n",
       "2017-01-09 00:00:00+00:00  0.003842 -0.003019 -0.003549  0.001949  0.000000\n",
       "2017-01-10 00:00:00+00:00  0.005209  0.001670  0.000000  0.003615 -0.007859\n",
       "2017-01-11 00:00:00+00:00  0.002062  0.005428  0.002830  0.002131  0.003276"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lvar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_metrics(data_port, risk_free=risk_free, mode='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_metrics(data_w_cripto_port, risk_free=risk_free, mode='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_indicators_for_all_portfolios(data_w_cripto, risk_free=risk_free, risk_limit=risk_limit, min_weight=min_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_indicators_for_all_portfolios(data, risk_free=risk_free, risk_limit=risk_limit, min_weight=min_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matriz de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlacion\n",
    "graficar_matriz_correlacion(data_w_cripto.pct_change().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Grafica Pastel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_portfolio_pies(data_w_cripto, risk_limit=risk_limit, min_weight=min_weight)\n",
    "plot_portfolio_pies(data, risk_limit=risk_limit, min_weight=min_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Frontera eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_frontera_eficiente(data_w_cripto, risk_free=risk_free, risk_limit=risk_limit, min_weight=min_weight, title='Portafolio de Indices con Criptomonedas')\n",
    "graficar_frontera_eficiente(data, risk_free=risk_free, risk_limit=risk_limit, min_weight=min_weight, title='Portafolio de Indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Rendimientos acumulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_returns(data_w_cripto_port, yticks=[1,1.5, 2, 3.5, 6, 11, 26, 51, 101, 201, 251, 301], num_minor_ticks=4)\n",
    "plot_cumulative_returns(data_port, yticks=[1,1.5, 2, 2.5, 3, 3.5, 4], num_minor_ticks=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Markov analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = markov_regresion(data, column='SP500', order=1, trend='n')\n",
    "data_lvar = test['l_var']\n",
    "data_hvar = test['h_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lvar_port = generate_portfolio_df(data_lvar,\n",
    "                        include_sharpe=True, \n",
    "                        include_min_vol=False, \n",
    "                        include_max_return=False,\n",
    "                        include_equal_weight=False, \n",
    "                        include_risk_limit=False, \n",
    "                        risk_free=risk_free, \n",
    "                        risk_limit=risk_limit,\n",
    "                        min_weight=min_weight,\n",
    "                        include_assets=False,\n",
    "                        save_weights=False,\n",
    "                        use_returns=True)\n",
    "data_lvar_w_cripto = add_cripto(data_lvar, cripto.pct_change().dropna(), ['BTC', 'ETH'])\n",
    "data_lvar_w_cripto_port = generate_portfolio_df(data_lvar_w_cripto,\n",
    "                        include_sharpe=True, \n",
    "                        include_min_vol=False, \n",
    "                        include_max_return=False,\n",
    "                        include_equal_weight=False, \n",
    "                        include_risk_limit=False, \n",
    "                        risk_free=risk_free, \n",
    "                        risk_limit=risk_limit,\n",
    "                        min_weight=min_weight,\n",
    "                        include_assets=False,\n",
    "                        save_weights=False,\n",
    "                        use_returns=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
